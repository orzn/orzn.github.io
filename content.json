{"meta":{"title":"orzn","subtitle":"兴趣使然","description":"望你走出半生，归来仍是少年","author":"John Doe","url":"http://orzn.github.io"},"pages":[],"posts":[{"title":"java是值传递还是引用传递","slug":"java-参数传递","date":"2018-08-06T02:42:10.000Z","updated":"2018-08-06T13:37:04.219Z","comments":true,"path":"2018/08/06/java-参数传递/","link":"","permalink":"http://orzn.github.io/2018/08/06/java-参数传递/","excerpt":"","text":"之前没有多想，一直以为java是引用传递。比如像这样：123456789public static void test(List&lt;Integer&gt; a)&#123; a.add(2);&#125;public static void main(String[] args) throws Exception &#123; List&lt;Integer&gt; aa = new ArrayList&lt;Integer&gt;(); aa.add(1); test(aa); System.out.println(aa);&#125; 最后，aa会加上2，输出结果是[1,2]。想起之前面试也被问到这个问题，我还肯定的说，在函数里对map修改，返回之后，肯定也能得到修改后的结果。但把上面test改一下：123public static void test(List&lt;Integer&gt; a)&#123; a = new ArrayList&lt;&gt;();&#125; 按之前想法，输出应该为空了，但实际上是[1]。为什么这样？ 因为java传递的是对象地址的拷贝，或者就理解为对象地址，但这个地址是不可变的，还称为值传递。所以，如果add()的话，就是在地址拷贝处加上了2，返回之后，输出时，看原对象地址后面会加了个2。但若在函数里重新指向一个地址，这里只是拷贝指向发生了变化，原结果不变。在看一个例子:123456789101112131415161718192021222324252627282930public class Dog &#123; String name; Dog(String name) &#123; this.name = name; &#125; void setName(String name )&#123; this.name = name; &#125; String getName() &#123; return name; &#125; String getObjectAddress() &#123; return super.toString(); &#125;&#125;public class PassByValueExample &#123; public static void main(String[] args) &#123; Dog dog = new Dog(&quot;A&quot;); //初始A System.out.println(dog.getObjectAddress()); //Dog@eac5a Dog@4554617c func(dog); System.out.println(dog.getObjectAddress()); //Dog@eac5a Dog@4554617c System.out.println(dog.getName()); //B &#125; private static void func(Dog dog) &#123; System.out.println(dog.getObjectAddress()); //Dog@eac5a Dog@4554617c dog.setName(&quot;B&quot;); System.out.println(dog.getObjectAddress()); //Dog@eac5a Dog@74a14482 System.out.println(dog.getName()); //B &#125;&#125; 重点是setName函数，这里dog地址没发生变化，拥有的name地址发生了变化，但我们在main函数里还可以通过dog来得到新的name。 但直接传递String就不行了，如下：12345678 public static void test(String a)&#123; a = &quot;1&quot;;&#125;public static void main(String[] args) throws Exception &#123; String a = &quot;123&quot;; test(a); System.out.println(a);&#125; 这里输出还是123。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://orzn.github.io/tags/java/"}]},{"title":"this和Thread.currentThread()的区别","slug":"java-this","date":"2018-07-21T15:10:10.000Z","updated":"2018-07-22T08:33:05.728Z","comments":true,"path":"2018/07/21/java-this/","link":"","permalink":"http://orzn.github.io/2018/07/21/java-this/","excerpt":"","text":"Thread.currentThread()获取的永远是当前线程的引用。this得到的是当前对象，当线程类继承了Thread，有时获取当前线程就可以用this替代。123456789101112131415161718192021222324252627282930313233343536373839public class MyThread extends Thread &#123; public MyThread()&#123; System.out.println(&quot;------&quot; + &quot;构造函数开始&quot; + &quot;------&quot;); System.out.println(&quot;Thread.currentThread().getName() = &quot; + Thread.currentThread().getName()); System.out.println(&quot;Thread.currentThread().isAlive() = &quot; + Thread.currentThread().isAlive()); System.out.println(&quot;this.getName() = &quot; + this.getName()); System.out.println(&quot;this.isAlive() = &quot; + this.isAlive()); System.out.println(&quot;------&quot; + &quot;构造函数结束&quot; + &quot;------&quot;); &#125; @Override public void run()&#123; Thread testThread = Thread.currentThread(); System.out.println(&quot;------&quot; + &quot;run()开始&quot; + &quot;------&quot;); System.out.println(&quot;Thread.currentThread().getName() = &quot; + Thread.currentThread().getName()); System.out.println(&quot;Thread.currentThread().isAlive() = &quot; + Thread.currentThread().isAlive()); System.out.println(&quot;this.getName() = &quot; + this.getName()); System.out.println(&quot;this.isAlive() = &quot; + this.isAlive()); System.out.println(&quot;Thread.currentThread() == this : &quot; + (Thread.currentThread() == this)); System.out.println(&quot;------&quot; + &quot;run()结束&quot; + &quot;------&quot;); &#125; &#125;public class Test &#123; public static void main(String[] args)&#123; MyThread myThread = new MyThread(); myThread.setName(&quot;A&quot;); myThread.start(); &#125;&#125; 输出结果： ——构造函数开始——Thread.currentThread().getName() = mainThread.currentThread().isAlive() = truethis.getName() = Thread-0this.isAlive() = false——构造函数结束————run()开始——Thread.currentThread().getName() = AThread.currentThread().isAlive() = truethis.getName() = Athis.isAlive() = trueThread.currentThread() == this : true——run()结束—— 我们看构造函数，Thread.currentThread()很好理解，就是调用构造方法的线程main。this得到的是MyThread，初始时，默认产生了个名字，而因为当时线程还没运行，因此isAlive()=false。运行开始后，run方法里的Thread.currentThread()和this实际上指的都是MyThread。修改测试类如下：123456789101112public class Test &#123; public static void main(String[] args)&#123; MyThread myThread = new MyThread(); // 将线程对象以构造参数的方式传递给Thread对象进行start（）启动线程 Thread newThread = new Thread(myThread); newThread.setName(&quot;A&quot;); newThread.start(); &#125;&#125; 测试结果： ——构造函数开始——Thread.currentThread().getName() = mainThread.currentThread().isAlive() = truethis.getName() = Thread-0this.isAlive() = false——构造函数结束————run()开始——Thread.currentThread().getName() = AThread.currentThread().isAlive() = truethis.getName() = Thread-0this.isAlive() = falseThread.currentThread() == this : false——run()结束—— 构造函数的测试结果没变，run方法变了。将线程对象以构造参数的方式传递给Thread对象进行start()启动线程，我们直接启动的线程实际是newThread，而作为构造参数的myThread，赋给Thread类中的属性target，之后在Thread的run方法中调用target.run()；此时Thread.currentThread()是Thread的引用newThread,而this依旧是MyThread的引用，所以是不一样的，打印的内容也不一样.","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://orzn.github.io/tags/java/"}]},{"title":"详解java内省","slug":"java-Introspector","date":"2018-07-19T09:50:10.000Z","updated":"2018-07-19T14:21:11.544Z","comments":true,"path":"2018/07/19/java-Introspector/","link":"","permalink":"http://orzn.github.io/2018/07/19/java-Introspector/","excerpt":"","text":"内省(IntroSpector)是Java语言对JavaBean类属性、事件的一种处理方法。例如类A中有属性name,那我们可以通过getName,setName来得到其值或者设置新的值。通过getName/setName来访问name属性，这就是默认的规则。内省访问JavaBean有两种方法： 通过PropertyDescriptor来操作Bean对象 12345678910111213141516 public class BeanInfoUtil &#123; public static void setProperty(UserInfo userInfo,String userName)throws Exception&#123; PropertyDescriptor propDesc=new PropertyDescriptor(userName,UserInfo.class);//制定要访问的属性名userName Method methodSetUserName=propDesc.getWriteMethod();//获取属性的写方法 methodSetUserName.invoke(userInfo, &quot;wong&quot;);//反射调用 System.out.println(&quot;set userName:&quot;+userInfo.getUserName()); &#125; public static void getProperty(UserInfo userInfo,String userName)throws Exception&#123; PropertyDescriptor proDescriptor =new PropertyDescriptor(userName,UserInfo.class); Method methodGetUserName=proDescriptor.getReadMethod(); Object objUserName=methodGetUserName.invoke(userInfo); System.out.println(&quot;get userName:&quot;+objUserName.toString()); &#125;&#125; 通过Introspector类获得Bean对象的 BeanInfo，然后通过 BeanInfo 来获取属性的描述器（ PropertyDescriptor ），通过这个属性描述器就可以获取某个属性对应的 getter/setter 方法，然后通过反射机制来调用这些方法。 123456789101112131415161718192021222324252627282930313233public class BeanInfoUtil &#123; public static void setPropertyByIntrospector(UserInfo userInfo,String userName)throws Exception&#123; BeanInfo beanInfo=Introspector.getBeanInfo(UserInfo.class);//获取类BeanInfo PropertyDescriptor[] proDescrtptors=beanInfo.getPropertyDescriptors(); if(proDescrtptors!=null&amp;&amp;proDescrtptors.length&gt;0)&#123; for(PropertyDescriptor propDesc:proDescrtptors)&#123; if(propDesc.getName().equals(userName))&#123; Method methodSetUserName=propDesc.getWriteMethod(); methodSetUserName.invoke(userInfo, &quot;alan&quot;); System.out.println(&quot;set userName:&quot;+userInfo.getUserName()); break; &#125; &#125; &#125; &#125; public static void getPropertyByIntrospector(UserInfo userInfo,String userName)throws Exception&#123; BeanInfo beanInfo=Introspector.getBeanInfo(UserInfo.class); PropertyDescriptor[] proDescrtptors=beanInfo.getPropertyDescriptors(); if(proDescrtptors!=null&amp;&amp;proDescrtptors.length&gt;0)&#123; for(PropertyDescriptor propDesc:proDescrtptors)&#123; if(propDesc.getName().equals(userName))&#123; Method methodGetUserName=propDesc.getReadMethod(); Object objUserName=methodGetUserName.invoke(userInfo); System.out.println(&quot;get userName:&quot;+objUserName.toString()); break; &#125; &#125; &#125; &#125; &#125; 可以看出，PropertyDescriptor需要属性名才能直接获取。而Introspector则可以获取全部属性的PropertyDescriptor。还可以用beanInfo.getMethodDescriptors()获取全部公开的成员方法。 JavaBean的出现，命名规范就是为了方便省事。apache，spring都提供了BeanUtils，此外还有PropertyUtil和cglib的BeanCopier，可以让我们更轻松的操作bean。如果觉得工具类不能满足需求，我们还可以自己重写方法，比如实现一个copy()函数。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://orzn.github.io/tags/java/"},{"name":"Introspector","slug":"Introspector","permalink":"http://orzn.github.io/tags/Introspector/"}]},{"title":"Spring静态注入的三种方法[转]","slug":"Spring-1","date":"2018-07-14T14:41:45.000Z","updated":"2018-07-14T17:56:15.248Z","comments":true,"path":"2018/07/14/Spring-1/","link":"","permalink":"http://orzn.github.io/2018/07/14/Spring-1/","excerpt":"","text":"Spring静态注入的三种方式： (说明：MongoFileOperationUtil是自己封装的一个Mongodb文件读写工具类，里面需要依赖AdvancedDatastore对象实例，dsForRW用来获取Mongodb数据源) 在springframework里，我们不能@Autowired一个静态变量,使之成为一个spring bean，例如下面这种方式：12@Autowiredprivate static AdvancedDatastore dsForRW; 可以试一下，dsForRW在这种状态下不能够被依赖注入，会抛出运行时异常java.lang.NullPointerException，为什么呢?静态变量/类变量不是对象的属性,而是一个类的属性,spring则是基于对象层面上的依赖注入。但是自己比较喜欢封装工具类，并通过@Component注解成功能组件，但是功能组件中的方法一般都是静态方法，静态方法只能调用静态成员变量，于是就有了下面的问题。封有的时候封装功能组件会需要底层的service注入，怎么办呢？去网上搜了下解决办法，简单总结一下几种实现方式； 1.xml方式实现；123&lt;bean id=&quot;mongoFileOperationUtil&quot; class=&quot;com.*.*.MongoFileOperationUtil&quot; init-method=&quot;init&quot;&gt; &lt;property name=&quot;dsForRW&quot; ref=&quot;dsForRW&quot;/&gt;&lt;/bean&gt; 12345678910public class MongoFileOperationUtil &#123; private static AdvancedDatastore dsForRW; private static MongoFileOperationUtil mongoFileOperationUtil; public void init() &#123; mongoFileOperationUtil = this; mongoFileOperationUtil.dsForRW = this.dsForRW; &#125;&#125; 这种方式适合基于XML配置的WEB项目； 2.@PostConstruct方式实现；12345678910111213141516import org.mongodb.morphia.AdvancedDatastore;import org.springframework.beans.factory.annotation.Autowired; @Componentpublic class MongoFileOperationUtil &#123; @Autowired private static AdvancedDatastore dsForRW; private static MongoFileOperationUtil mongoFileOperationUtil; @PostConstruct public void init() &#123; mongoFileOperationUtil = this; mongoFileOperationUtil.dsForRW = this.dsForRW; &#125; &#125; @PostConstruct 注解的方法在加载类的构造函数之后执行，也就是在加载了构造函数之后，执行init方法；(@PreDestroy 注解定义容器销毁之前的所做的操作)这种方式和在xml中配置 init-method和 destory-method方法差不多，定义spring 容器在初始化bean 和容器销毁之前的所做的操作； 3.set方法上添加@Autowired注解，类定义上添加@Component注解；1234567891011121314import org.mongodb.morphia.AdvancedDatastore;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component; @Componentpublic class MongoFileOperationUtil &#123; private static AdvancedDatastore dsForRW; @Autowired public void setDatastore(AdvancedDatastore dsForRW) &#123; MongoFileOperationUtil.dsForRW = dsForRW; &#125;&#125; 首先Spring要能扫描到AdvancedDatastore的bean，然后通过setter方法注入；然后注意：成员变量上不需要再添加@Autowired注解； ps: Spring中用@Component,@Service等标注的默认bean名称会是小写开头的非限定类名。注意别和配置文件里的bean重名了。。。。。。","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://orzn.github.io/tags/Spring/"}]},{"title":"java序列化须知","slug":"java-serializable","date":"2018-07-11T11:57:10.000Z","updated":"2018-07-12T15:00:28.365Z","comments":true,"path":"2018/07/11/java-serializable/","link":"","permalink":"http://orzn.github.io/2018/07/11/java-serializable/","excerpt":"","text":"子类父类 若父类实现了Serializable，子类不需要实现Serializable即可实现序列化。反之，父类未实现，子类实现了，序列化时，不会序列化父类的属性。如果父类不实现序列化，就必须有默认的无参构造函数，否则子类在继承Serializable接口后会报错。若想序列化父类的属性，需要自己实现writeObject(ObjectOutputStream out)和readObject(ObjectInputStream in)。如下：12345678private void writeObject(java.io.ObjectOutputStream out) throws IOException&#123; out.defaultWriteObject();//先序列化对象 out.writeInt(supervalue);//再序列化父类的域 &#125; private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException&#123; in.defaultReadObject();//先反序列化对象 supervalue=in.readInt();//再反序列化父类的域&#125; 这样在序列化时就会被调用，以代替默认的行为。 静态变量 java序列化时不会序列化静态变量，因为其属于类，不属于对象。 Externalizable接口 还有个Externalizable接口，其与Serializable接口类似，只是Externalizable接口需要强制自定义序列化。如下：123456789@Overridepublic void writeExternal(ObjectOutput out) throws IOException &#123; out.writeObject(new StringBuffer(name).reverse()); //将name简单加密&#125;@Overridepublic void readExternal(ObjectInput in) throws IOException, ClassNotFoundException &#123; name = ((StringBuffer) in.readObject()).reverse().toString();&#125; 单例模式 序列化可能会破坏单例模式，解决方法有两个： 一个加readResolve 一个是用枚举方法实现单例 123456789101112131415161718public class Singleton implements Serializable&#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; private Object readResolve() &#123; return singleton; &#125;&#125; 使用枚举类实现单例模式，在对枚举类进行序列化时，还不需要添加readRsolve方法就可以避免单例模式被破坏。12345678910111213public enum SingletonClass implements Serializable &#123; INSTANCE; private static final long serialVersionUID = 1L; private String name; public void test() &#123; System.out.println(&quot;The Test!&quot;); &#125; public void setName(String name) &#123; this.name = name; &#125; public String getName() &#123; return name;&#125; 枚举类很好的解决了这两个问题，使用枚举除了线程安全和防止反射调用构造器之外，还提供了自动序列化机制，防止反序列化的时候创建新的对象。因此，《Effective Java》作者推荐使用的方法。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://orzn.github.io/tags/java/"},{"name":"serializable","slug":"serializable","permalink":"http://orzn.github.io/tags/serializable/"}]},{"title":"CDN","slug":"CDN","date":"2018-07-10T15:04:00.000Z","updated":"2018-07-10T15:38:59.905Z","comments":true,"path":"2018/07/10/CDN/","link":"","permalink":"http://orzn.github.io/2018/07/10/CDN/","excerpt":"","text":"因为在公司项目代码里看到了CDN，对此也不了解，遂记之。 CDN，全称Content Delivery Network，内容分发网络。是将网站内容分发至最接近用户的节点，使用户可就近取得所需内容，提高用户访问的响应速度和成功率。解决因分布、带宽、服务器性能带来的访问延迟问题，适用于站点加速、点播、直播等场景。当用户访问某网站时，url经服务器解析获取对应cname域名，而这里的cname指向的是CDN负载均衡设备的IP地址。该服务器会为用户选择一台合适的缓存服务器，用户向该服务器发出请求。若此服务器没有缓存用户想要的内容，会向上一级请求，并将内容拉到本地。流程如下图： 先这样。","categories":[],"tags":[{"name":"CDN","slug":"CDN","permalink":"http://orzn.github.io/tags/CDN/"}]},{"title":"从ejb到soa","slug":"ejb-rmi-soa","date":"2018-07-07T10:30:08.000Z","updated":"2018-07-14T17:37:25.130Z","comments":true,"path":"2018/07/07/ejb-rmi-soa/","link":"","permalink":"http://orzn.github.io/2018/07/07/ejb-rmi-soa/","excerpt":"","text":"之前提到tomcat不支持j2ee，指的是tomcat不支持EJB。那么问题来了，EJB是啥？ EJB的概念EJB，Enterprise JavaBean，是一种描述了构建应用组件要解决的标准。是一个放在服务器端、封装了业务逻辑的组件，供客户端去调用。EJB不仅仅可作为B/S结构的应用，也可作为C/S结构的应用。该规范描述了分布式应用程序需要解决的问题，如事务处理、安全、日志、分布式等，同时SUN公司也实现了自己定义的标准。客户端是通过网络对EJB对象进行调用，而EJB技术基础正是RMI。通过RMI技术，J2EE将EJB组件创建为远程对象，客户端就可以通过网络调用EJB对象了。 RMI的概念RMI是（Remote Method Invocation）远程方法调用。它就是利用Java 对象序列化的机制实现分布式计算，实现远程类对象的实例化以及调用的方法。说的更清楚些，就是利用对象序列化来实现远程调用，利用这个方法来调用远程的类的时候，就不需要编写Socket 程序了，也不需要把对象进行序列化操作，直接调用就行了非常方便。RMI是JDK1.1就已经诞生的产物，且是基于Java的，只有在Server和clinet端都用Java时才能用。也可以看做一个RPC实现。 SOA的概念SOA(Service-Oriented Architecture)，即面向服务的架构。其中包含多个服务，而服务之间通过配合最终会提供一系列功能。一个服务通常以独立的形式存在于操作系统进程中。服务之间通过网络调用，而非采用进程内调用的方式进行通信。看图其实很清楚。 所有的服务都向数据总线注册，各子系统再根据统一标准找其他系统。好处很明显，程序之间关系服务简单。数据总线除了服务注册，还会有心跳检测，负载均衡等等。很明显，SOA也可以用RMI来实现。","categories":[],"tags":[{"name":"ejb","slug":"ejb","permalink":"http://orzn.github.io/tags/ejb/"},{"name":"rmi","slug":"rmi","permalink":"http://orzn.github.io/tags/rmi/"},{"name":"soa","slug":"soa","permalink":"http://orzn.github.io/tags/soa/"}]},{"title":"tomcat与resin","slug":"tomcat-resin-web容器","date":"2018-07-07T04:27:07.000Z","updated":"2018-07-07T10:28:42.521Z","comments":true,"path":"2018/07/07/tomcat-resin-web容器/","link":"","permalink":"http://orzn.github.io/2018/07/07/tomcat-resin-web容器/","excerpt":"","text":"Tomcat是Apache鼎力支持的Java Web应用服务器，由于有了Sun的参与和支持，最新的Servlet和JSP规范总是能在Tomcat中得到体现，而且性能稳定，免费，又由于它优秀的稳定性以及丰富的文档资料，广泛的使用人群，从而在开源领域受到最广泛的青睐。 Tomcat运行时占用的系统资源小，扩展性好，支持负载平衡与邮件服务等开发应用系统常用的功能；而且它还在不断的改进和完善中，任何一个感兴趣的程序员都可以更改它或在其中加入新的功能。 Resin也仅仅是一个Servlet容器，然而由于它优秀的运行速度，使得它在轻量级Java Web领域备受喜爱，特别是在互联网Web服务领域，众多知名公司都采用其作为他们的Java Web应用服务器，譬如163、ku6等。 Resin也可以和许多其他的WEB服务器一起工作，比如Apache server和IIS等。Resin支持负载平衡（Load balancing），可以增加WEB站点的可靠性。方法是增加服务器的数量。比如一台SERVER的错误率是1%的话，那么支持负载平衡的两个Resin服务器就可以使错误率降到0.01%。 总的来说，有这么几个区别： resin速度快 resin报错十分简洁明确 resin对中文支持好 resin支持自动编译Servlet和bean tomcat还不支持j2ee，至少在6以前还是这样的。","categories":[],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://orzn.github.io/tags/tomcat/"},{"name":"resin","slug":"resin","permalink":"http://orzn.github.io/tags/resin/"},{"name":"web容器","slug":"web容器","permalink":"http://orzn.github.io/tags/web容器/"}]},{"title":"MongoDB入门","slug":"MongoDB-1","date":"2018-06-30T07:36:20.000Z","updated":"2018-06-30T18:55:55.176Z","comments":true,"path":"2018/06/30/MongoDB-1/","link":"","permalink":"http://orzn.github.io/2018/06/30/MongoDB-1/","excerpt":"","text":"1、相关基本概念 MongoDB 是一个基于分布式文件存储的数据库。由 C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。 MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。 RDBMS NoSQL 高度组织化结构化数据 没有预定义的模式 结构化查询查询语言 没有声明性查询语言 严格的一致性 最终一致性，非ACID属性 基础事务 高性能，高可用性和可伸缩性 数据和关系存储在单独的表中 键值对存储，列存储，文档存储，图形数据库。 上面是关系型数据库和非关系型数据库的一些特点对比，有些也不是很对应，看看就好。MongoDB是个分布式文件存储结构，也满足CAP定理。 CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。 NoSQL的优点： 高可扩展性 分布式计算 低成本 架构的灵活性，半结构化数据 没有复杂的关系 缺点： 没有标准化 有限的查询功能（so far） 最终一致是不直观的程序 在这儿对一些常用的NoSQL数据库进行总结： 类型 代表 特点 列存储 Hbase Cassandra 顾名思义，是按列存储数据的。最大的特点是方便存储结构化和半结构化数据，方便做数据压缩，对针对某一列或者某几列的查询有非常大的IO优势。 键值对存储 Redis MemcacheDB 可以通过key快速查询到其value，存储和不管value的格式 图存储 Neo4J FlockDB 图形关系的最佳存储，使用传统关系数据库来解决的话性能低下 文档存储 MongoDB CouchDB 文档存储一般用类似json的格式存储，内容是文档型的。这样也就有有机会对某些字段建立索引，实现关系数据库的某些功能。 对象存储 db4o Versant 通过类似面向对象语言的语法操作数据库，通过对象的方式存取数据。 xml数据库 Berkeley DB 高效的存储XML数据，并支持XML的内部查询语法，如XQuery, Xpath。 2、MongoDB简介 MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于JSON对象。字段值可以包含其他文档，数组及文档数组。 MongoDB 安装完成后，通过MongoDB Shell来对MongoDB进行操作和管理，当./mongo进入后台后，它默认会链接到test文档（数据库）。 MongoDB概念 SQL术语 MongoDB术语 解释 database database 数据库 table collection 数据库表/集合 row document 数据库记录行/文档 colume field 数据字段/域 index index 索引 table joins 表连接，MongoDB不支持 primary key primary key 主键，MongoDB自动将_id字段设置为主键 通过下图实例，我们也可更直观的了解Mongo中的一些概念： 数据库 一个mongoDB中可以建立多个数据库，MongoDB的默认数据库为db。MongoDB的单个实例可以容纳多个独立的数据库，每一个都有自己的集合和权限，不同的数据库也放置在不同的文件中。 show dbs 命令可以显示所有数据库库的列表 db 显示当前数据库对象或集合 use 数据库名 连接到一个指定的数据库 mongodb中有一些保留的数据库名。 admin： 当Mongod启用auth选项时，用户需要创建数据库帐号，访问时根据帐号信息来鉴权，而数据库帐号信息就存储在admin数据库下。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。 local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合. config：当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。 文档 文档，即一条记录，通常意义上的一行数据。MongoDB的文档不需要设置相同的字段，相同的字段不需要相同的数据类型，这与关系型数据库有很大的区别，也是 MongoDB 非常突出的特点。 集合 集合就是 MongoDB 文档组，即表。集合没有固定的结构，这意味着你在对集合可以插入不同格式和类型的数据，但通常情况下我们插入集合的数据都会有一定的关联性。比如，我们可以将以下不同数据结构的文档插入到集合中： {“site”:”www.baidu.com”}{“site”:”www.google.com”,”name”:”Google”}{“site”:”www.runoob.com”,”name”:”菜鸟教程”,”num”:5} 集合名不能为空，不能含有\\0字符，这个字符表示集合名的结尾，集合不能以“system”开头，这是系统保留字符。集合中有个Capped collections，即固定大小的collection。它有很高的性能以及队列过期的特性。它非常适合类似记录日志的功能 和标准的collection不同，你必须要显式的创建一个capped collection， 指定一个collection的大小，单位是字节。collection的数据存储空间值提前分配的。1db.createCollection(&quot;mycoll&quot;, &#123;capped:true, size:100000&#125;) capped collections不允许删除文档（行），但可以drop()掉所有行。 元数据 数据库的一些信息。它们使用了系统的命名空间：dbname.system.*。 集合命名空间 描述 dbname.system.namespaces 列出所有名字空间 dbname.system.indexes 列出所有索引 dbname.system.profile 包含数据库概要信息 dbname.system.users 列出所有可访问数据库的用户 dbname.local.sources 包含复制对端（slave）的服务器信息和状态。 数据类型 String,Integer,Boolean,Double,Min/Max keys（将一个值与 BSON（二进制的 JSON）元素的最低值和最高值相对比。）,Array（将数组或列表或多个值存储为一个键）,Timestamp（记录文档修改或添加的具体时间）,Object（用于内嵌文档）,Null,Symbol（该数据类型基本上等同于字符串类型，但不同的是，它一般用于采用特殊符号类型的语言。）,Date,Object ID（对象 ID。用于创建文档的 ID。）,Binary Data（二进制数据。用于存储二进制数据。）,Code（代码类型。用于在文档中存储 JavaScript 代码。）,Regular expression（正则表达式类型。用于存储正则表达式。）。 时间戳要用于 MongoDB 内部使用。在大多数情况下的应用开发中，你可以使用 BSON 日期类型。日期，表示当前距离 Unix新纪元（1970年1月1日）的毫秒数。日期类型是有符号的, 负数表示 1970 年之前的日期。 3、基本操作12345678910111213141516171819202122232425262728use test //创建test数据库或切换此数据库db.test.insert(&#123;&quot;name&quot;:&quot;小明&quot;&#125;) //插入数据，若集合test不存在，会创建show dbs //只有有数据的数据库才显示db.dropDatabase() //删除当前数据库show tables //显示当前数据库中的集合（表）db.collection.drop() //删除集合collectiondb.createCollection(name,options) //name是集合名称 db.createCollection(&quot;mycol&quot;, &#123; capped : true, autoIndexId : true, size : 6142800, max : 10000 &#125; ) //指定capped，必须设定size, max指集合中包含文档的最大数量。db.col.insert(&#123;title: &apos;MongoDB 教程&apos;, description: &apos;MongoDB 是一个 Nosql 数据库&apos;, by: &apos;菜鸟教程&apos;, url: &apos;http://www.runoob.com&apos;, tags: [&apos;mongodb&apos;, &apos;database&apos;, &apos;NoSQL&apos;], likes: 100&#125;) //col是集合，若集合不在数据库中，会自动创建该集合并插入文档db.col.find() //读取文档db.col.update(&#123;&apos;title&apos;:&apos;MongoDB 教程&apos;&#125;,&#123;$set:&#123;&apos;title&apos;:&apos;MongoDB&apos;&#125;&#125;) //更新titledb.col.save(&#123; &quot;_id&quot; : ObjectId(&quot;56064f89ade2f21f36b03136&quot;), &quot;title&quot; : &quot;MongoDB&quot;,&#125;) //更新此id的数据db.col.remove(&#123;&apos;title&apos;:&apos;MongoDB 教程&apos;&#125;) //删除db.col.remove(&#123;&#125;) //删除所有//条件操作符 &gt; $gt ; &lt; $lt ; &gt;= $gte ; &lt;= $lte db.col.find(&#123;&quot;likes&quot; : &#123;$gt : 100&#125;&#125;) db.col.find(&#123;likes : &#123;$lt :200, $gt : 100&#125;&#125;)db.col.find(&#123;$or:[&#123;&quot;by&quot;:&quot;菜鸟教程&quot;&#125;,&#123;&quot;title&quot;: &quot;MongoDB 教程&quot;&#125;]&#125;).pretty() //$or就是ordb.col.find(&#123;&quot;likes&quot;: &#123;$gt:50&#125;, $or: [&#123;&quot;by&quot;: &quot;菜鸟教程&quot;&#125;,&#123;&quot;title&quot;: &quot;MongoDB 教程&quot;&#125;]&#125;).pretty()","categories":[],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://orzn.github.io/tags/MongoDB/"},{"name":"database","slug":"database","permalink":"http://orzn.github.io/tags/database/"}]},{"title":"netty之hellworld（二）","slug":"netty-2","date":"2018-06-10T06:31:10.000Z","updated":"2018-08-05T08:58:21.729Z","comments":true,"path":"2018/06/10/netty-2/","link":"","permalink":"http://orzn.github.io/2018/06/10/netty-2/","excerpt":"","text":"直接通过一个简单的helloworld程序来学习netty的使用，实现一个server输出并返回client的数据。用的netty版本是4.0.21.Final。12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.0.21.Final&lt;/version&gt;&lt;/dependency&gt; 先实现HelloWorldServer12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class HelloWorldServer &#123; private int port; public HelloWorldServer(int port) &#123; this.port = port; &#125; public void start()&#123; /* 这里定义了两个工作线程池，一个bossGroup，一个workerGroup。每个线程负责处理多个channel。boss线程负责处理来自这两个端口的请求，boss线程接受了socket连接后，会创建一个channel, 之后会有worker线程来继续处理socket请求。 如果是NioServerSocketChannelFactory的话，每个worker可以服务不同的socket或者说channel，worker线程和channel不再有一一对应的关系。显然，NioServerSocketChannelFactory只需要少量活动的worker线程及能很好的处理众多的channel，而OioServerSocketChannelFactory则需要与打开channel等量的worker线程来服务。 */ EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; /*ServerBootstrap负责初始化netty服务器，并监听端口的socket请求，ServerBootstrap有两个EventLoopGroup */ ServerBootstrap sbs = new ServerBootstrap().group(bossGroup,workerGroup) .channel(NioServerSocketChannel.class) //使用的NIO传输channel .localAddress(new InetSocketAddress(port)) //设置socket地址 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; //服务端初始化程序 protected void initChannel(SocketChannel ch) throws Exception &#123;// ch.pipeline().addLast(&quot;framer&quot;, new DelimiterBasedFrameDecoder(8192, Delimiters.lineDelimiter())); ch.pipeline().addLast(&quot;decoder&quot;, new StringDecoder()); //解码 ch.pipeline().addLast(&quot;encoder&quot;, new StringEncoder()); //编码 ch.pipeline().addLast(new HelloWorldServerHandler()); //添加自己的处理函数 &#125;; &#125;).option(ChannelOption.SO_BACKLOG, 128) // .childOption(ChannelOption.SO_KEEPALIVE, true); // 绑定端口，开始接收进来的连接 ChannelFuture future = sbs.bind(port).sync(); //sync() 等待bind完成 System.out.println(&quot;Server start listen at &quot; + port ); //监听服务器关闭监听 future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; int port; if (args.length &gt; 0) &#123; port = Integer.parseInt(args[0]); &#125; else &#123; port = 8080; &#125; new HelloWorldServer(port).start(); &#125;&#125; 然后是服务器处理函数：12345678910111213141516171819public class HelloWorldServerHandler extends ChannelInboundHandlerAdapter&#123; /*收到消息之后处理*/ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(&quot;server channelRead..&quot;); System.out.println(ctx.channel().remoteAddress()+&quot;-&gt;Server :&quot;+ msg.toString()); //写消息并发送给客户端 ctx.write(&quot;server write&quot;+msg); ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 客户端代码：1234567891011121314151617181920212223242526272829303132333435363738394041public class HelloWorldClient &#123; static final String HOST = System.getProperty(&quot;host&quot;, &quot;127.0.0.1&quot;); static final int PORT = Integer.parseInt(System.getProperty(&quot;port&quot;, &quot;8080&quot;)); static final int SIZE = Integer.parseInt(System.getProperty(&quot;size&quot;, &quot;256&quot;)); public static void main(String[] args) throws Exception &#123; // Configure the client. EventLoopGroup group = new NioEventLoopGroup(); try &#123; //Bootstrap只有一个EventLoopGroup, 负责创建管道给客户 Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) //使用的NIO传输channel .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline p = ch.pipeline(); p.addLast(&quot;decoder&quot;, new StringDecoder()); p.addLast(&quot;encoder&quot;, new StringEncoder()); p.addLast(new HelloWorldClientHandler()); &#125; &#125;); ChannelFuture future = b.connect(HOST, PORT).sync(); String comment = &quot;&quot;; Scanner sc = new Scanner(System.in); while(sc.hasNextLine())&#123; comment = sc.nextLine(); future.channel().writeAndFlush(comment); &#125; future.channel().closeFuture().sync(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 客户端处理程序：12345678910111213141516171819public class HelloWorldClientHandler extends ChannelInboundHandlerAdapter &#123; //客户端开启的时候打印 @Override public void channelActive(ChannelHandlerContext ctx) &#123; System.out.println(&quot;HelloWorldClientHandler Active&quot;); &#125; //客户端读取到服务端信息时打印 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; System.out.println(&quot;HelloWorldClientHandler read Message:&quot; + msg); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 测试的时候，先启动服务端，显示： Server start listen at 8080 表明服务端正常启动，然后开启客户端，可输入一行数据，并得到服务端的反馈信息。","categories":[],"tags":[{"name":"netty","slug":"netty","permalink":"http://orzn.github.io/tags/netty/"}]},{"title":"netty初探（一）","slug":"netty-1","date":"2018-06-10T06:30:10.000Z","updated":"2018-07-29T04:56:18.092Z","comments":true,"path":"2018/06/10/netty-1/","link":"","permalink":"http://orzn.github.io/2018/06/10/netty-1/","excerpt":"","text":"Netty的概念 Netty是一个提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。Netty基于NIO，能够更简单地处理大容量数据流；能够更简单地处理协议编码和单元测试；应用程序的关闭更简单，更安全；I/O超时和idle状态检测；更可靠的OutOfMemoryError预防。 还有个Mina，和Netty类似。他们架构差别不大。 但netty文档更清晰，使用更简单，Netty里你可以自定义的处理upstream events 或/和downstream events，可以使用decoder和encoder来解码和编码发送内容 Mina将内核和一些特性的联系过于紧密，使得用户在不需要这些特性的时候无法脱离，相比下性能会有所下降，Netty解决了这个设计问题 Netty和Mina在处理UDP时有一些不同，Netty将UDP无连接的特性暴露出来；而Mina对UDP进行了高级层次的抽象，可以把UDP当成”面向连接”的协议，而要Netty做到这一点比较困难。 相关概念介绍 前面提到了NIO，这里就多聊几句同步异步，阻塞非阻塞之间的关系。同步异步关注的是消息通信机制，若同步，则调用结束前不返回，而异步则通过状态或回调函数来处理这个调用。阻塞非阻塞指程序等待消息时的状态，若阻塞，则线程会被挂起，和同步不同，同步的线程还可以是激活的，可以干别的事情。知乎上有个例子有形象。怎样理解阻塞非阻塞与同步异步的区别？ 然后，我们看下BIO，NIO，AIO这三个概念。 BIO：同步阻塞模型。通常由一个独立的Acceptor线程负责监听客户端的连接，它接收到客户端的连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。 NIO：同步非阻塞模型。和BIO不同的是，当有连接请求时会注册到多路复用器上而不创建新线程，只有发生请求时才开启线程进行处理。 AIO：异步非阻塞模型。这个是JDK1.7之后升级了NIO类库，引入了异步通道这个概念 Netty的传输也依赖了NIO的一个特性———零拷贝。一般我们的数据如果需要从IO读取到堆内存，中间需要经过Socket缓冲区，也就是说一个数据会被拷贝两次才能到达他的的终点，如果数据量大，就会造成不必要的资源浪费。对此，Netty就在堆内存外开辟一个内存区域————直接内存，通过ByteBuf对这些数据进行操作，从而加快传输速度。 Netty的组成Channel Channel是NIO的基本结构，代表了一个连接，可以理解为每个请求。请求通过一个个ChannelHandler进行处理，而用来保存处理过程需要用到的ChannelHandler就是ChannelPipeline，来的消息经过pipeline，发送的消息也会经过pipeline。Netty也提供了一组丰富的预定义的处理程序,您可以开箱即用。比如，各种协议的编解码器包括HTTP和SSL/TLS。 ByteBuf 这个是NIO中的东西，是一个存储字节的容器，最大特点就是使用方便，它既有自己的读索引和写索引，方便你对整段字节缓存进行读写，也支持get/set，方便你对其中每一个字节进行读写。 Future JDK附带接口java.util.concurrent.Future ,但所提供的实现只允许您手动检查操作是否完成或阻塞了。这是很麻烦的，所以Netty提供了自己的实现,ChannelFuture,用于在执行异步操作时使用。每个Netty的outbound I/O操作都会返回一个ChannelFuture;这样就不会阻塞。这就是Netty所谓的“自底向上的异步和事件驱动”。 Callback callback(回调)是一个简单的方法,提供给另一种方法作为引用,这样后者就可以在某个合适的时间调用前者。这种技术被广泛使用在各种编程的情况下,最常见的方法之一通知给其他人操作已完成。Netty 内部使用回调处理事件时。一旦这样的回调被触发，事件可以由接口ChannelHandler的实现来处理。如下面的代码，一旦一个新的连接建立了,调用channelActive(),并将打印一条消息。1234567public class ConnectHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; //1 System.out.println( &quot;Client &quot; + ctx.channel().remoteAddress() + &quot; connected&quot;); &#125;&#125;","categories":[],"tags":[{"name":"netty","slug":"netty","permalink":"http://orzn.github.io/tags/netty/"}]},{"title":"protobuf和protostuff简介[转]","slug":"protobuf-serializable","date":"2018-06-08T14:32:21.000Z","updated":"2018-06-08T14:42:13.646Z","comments":true,"path":"2018/06/08/protobuf-serializable/","link":"","permalink":"http://orzn.github.io/2018/06/08/protobuf-serializable/","excerpt":"","text":"在我们的开发过程中，序列化是经常需要处理的问题，比如在做分布式访问数据时，或者是在做redis缓存存储数据时，如果我们涉及的知识面不够广的话，可能会简单的使用JDK的序列化，也即在需要序列化的类上implements Serializable接口去实现序列化，我想说的是这种方式在小系统中尚且可以用一用，如果是并发很大的系统会受到严重影响，这是由于JDK自带的序列化效率很低，不论是时间上还是空间上。我们经常使用的序列化方式还有XML和Json，说实在的我更多的是使用Json，我觉得它很方便很友好，但这些都不够好，我今天要将的是google开发的开源的序列化方案protocol buffer（简称protobuf），它的好处很多，独立于语言，独立于平台，最最重要的是它的效率相当高，用protobuf序列化后的大小是json的10分之一，xml格式的20分之一，是二进制序列化的10分之一，是不是很心动。其实我也刚接触这个好东西，写下此篇博客就当一个学习笔记吧。protobuf使用起来非常简单，它的主要流程是：我们需要自己写一个.proto文件用来描述序列化的格式，然后用protobuf提供的protoc工具将.proto文件编译成一个Java文件（protobuf官方支持很多语言：Java、C++、C#、Go、Python ，protobuf是一个开源项目，因此有很多大牛也实现了其他语言，但它们的可靠性还有待验证），最后将该Java文件引入到我们的项目中就可以使用了，当然还得引入protobuf的依赖包。 我们需要到官网下载protobuf的相应版本，我这里下载的是windows下的3.1.0版protoc-3.1.0-win32.zip 将下载好的zip解压，能看到bin目录下有一个protoc.exe的文件，等下需要用它来编译文件，我们直接在bin目录下 创建一个简单的person.proto的描述文件，内容如下： 1234567891011121314 syntax = &quot;proto3&quot;; option java_package = &quot;gudao.red.protobuf&quot;; option java_outer_classname = &quot;PersonFactory&quot;; message Person&#123; int32 id = 1; string name = 2; int32 age = 3; Addr addr = 4; &#125; message Addr&#123; string contry = 1; string city = 2; &#125; 内容非常简单，大概介绍一下：syntax = “proto3”; 我们使用proto3版协议option java_package = “gudao.red.protobuf”;编译之后生成的Java文件的包名option java_outer_classname = “PersonFactory”;编译之后生成的Java类的类名message 相当于Java中的class详细的介绍，还请自行去官网查看。 使用protoc编译上述.proto文件，生成Java类，使用如下命令完成该操作 1protoc --java_out=./src ./person.proto –java_out:生成的Java文件输出的位置，其他语言有相应的选项。这样就会在src目录下生成一个 名为PersonFactory的Java文件。 将PersonFactory.java文件引入到我们的项目中，并引入对应版本的protobuf的依赖包 写测试代码 1234567891011121314151617181920212223242526272829303132333435363738394041 public class Client &#123; public static void main(String[] args) throws Exception &#123; Socket socket = new Socket(&quot;127.0.0.1&quot;,3030); Person.Builder person = Person.newBuilder(); Addr.Builder addr = Addr.newBuilder(); addr.setContry(&quot;china&quot;).setCity(&quot;shenzhen&quot;); person.setId(1).setAge(12).setName(&quot;ccf&quot;); person.setAddr(addr); byte[] messageBody = person.build().toByteArray(); int headerLen = 1; byte[] message = new byte[headerLen+messageBody.length]; message[0] = (byte)messageBody.length; System.arraycopy(messageBody, 0, message, 1, messageBody.length); System.out.println(&quot;msg len:&quot;+message.length); socket.getOutputStream().write(message); &#125; &#125; ......public class Server &#123; public static void main(String[] args) throws Exception &#123; // TODO Auto-generated method stub ServerSocket serverSock = new ServerSocket(3030); while(true)&#123; Socket sock = serverSock.accept(); byte[] msg = new byte[256]; sock.getInputStream().read(msg); int msgBodyLen = msg[0]; System.out.println(&quot;msg body len:&quot;+msgBodyLen); byte[] msgbody = new byte[msgBodyLen]; System.arraycopy(msg, 1, msgbody, 0, msgBodyLen); Person person = Person.parseFrom(msgbody); System.out.println(&quot;Receive:&quot;); System.out.println(person); &#125; &#125; &#125; 先后启动Server和Client，就可以看到控制台的输出如下： 至此，我们的简单使用过程就完成了，是不是很简单。是，这个例子看上去是挺简单的，但如果我们需要序列化的类非常多，那么我们是不是得写非常多的.proto文件，并且还需要更新它们，这个代价可以想象一下也是非常大的。那么，接下来我们就来讲一讲protostuff，看这名字是不是跟protobuf很像，嗯，它们是有关系，前者就是基于后者实现的。 protostuff是一个基于protobuf实现的序列化方法，它较于protobuf最明显的好处是，在几乎不损耗性能的情况下做到了不用我们写.proto文件来实现序列化。使用它也非常简单，所以直接上代码。 12345678910111213141516171819202122public class ProtostuffTest &#123; static RuntimeSchema&lt;Po&gt; poSchema = RuntimeSchema.createFrom(Po.class); private static byte[] decode(Po po)&#123; return ProtostuffIOUtil.toByteArray(po, poSchema, LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE)); &#125; private static Po ecode(byte[] bytes)&#123; Po po = poSchema.newMessage(); ProtostuffIOUtil.mergeFrom(bytes, po, poSchema); return po; &#125; public static void main(String[] args) &#123; InnerPo innerPo = new InnerPo(1, &quot;InnerPo1&quot;); List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); Po po = new Po(1, &quot;Fong&quot;, &quot;备注&quot;, 24, new int[]&#123;1,2,3,4&#125;,innerPo,list); byte[] bytes = decode(po); System.out.println(bytes.length); Po newPo = ecode(bytes); System.out.println(newPo); &#125; &#125;","categories":[],"tags":[{"name":"serializable","slug":"serializable","permalink":"http://orzn.github.io/tags/serializable/"},{"name":"protobuf","slug":"protobuf","permalink":"http://orzn.github.io/tags/protobuf/"}]},{"title":"redis入门","slug":"redis-1","date":"2018-06-03T06:40:21.000Z","updated":"2018-06-08T14:08:20.314Z","comments":true,"path":"2018/06/03/redis-1/","link":"","permalink":"http://orzn.github.io/2018/06/03/redis-1/","excerpt":"","text":"Redis简介Redis是一个开源的，高性能的Key-Value存储系统。Redis的所有操作都是原子性的，同时还支持对几个操作合并后的原子性执行。与其他key-value缓存产品相比，还有以下三个特点： Redis支持数据持久化，可将数据保存在磁盘中，重启时再次加载进行使用。 Redis不仅仅支持简单类型数据，同时还提供了list,set,zset,hash等数据结构。 支持数据备份，即master-slave模式的数据备份。 Redis支持五种数据类型，string，hash，list，set及zset(有序集合)。 String string类型是二进制安全的，意思是string可以包含任何数据。比如jpg或者序列化后的对象。一个键最大能存储512MB。 123redis 127.0.0.1:6379&gt; SET name &quot;dd&quot;redis 127.0.0.1:6379&gt; GET name&quot;dd&quot; Hash hash即hashmap。使用HMSET，HGET命令赋值读取。 123redis 127.0.0.1:6379&gt; HMSET myhash field1 &quot;hello&quot; field2 &quot;world&quot;redis 127.0.0.1:6379&gt; HGET myhash field1&quot;hello&quot; List list是字符串列表，可用LPUSH，PPUSH在列表前后添加元素，用LRANGE获取指定范围内的元素。列表最后存储2的32次方-1个元素。 Set 用sadd进行添加，smembers查看元素集合。 zset zset中每一个元素会关联一个double类型的分数，redis通过分数为集合中的元素进行排序，分数可以重复。 1zadd key score member Java使用redis 要在Java中使用redis，需要jedis.jar。操作很简单，如下： 12345Jedis jedis = new Jedis(&quot;192.168.1.10&quot;,6379);jedis.auth(&quot;123456&quot;); //passwordjedis.set(&quot;name&quot;,&quot;jedis&quot;);String value = jedis.get(&quot;name&quot;);jedis.close(); 还可以用redisPool连接池。 12345678910111213141516171819202122232425262728 public class TestJedis &#123; public static void main(String[] args) &#123; JedisPoolConfig jpconfig= new JedisPoolConfig();//初始化连接池 jpconfig.setMaxTotal(100);//设置最大连接数 jpconfig.setMaxIdle(10);//设置最大空闲连接数 JedisPool jedisPool = new JedisPool(jpconfig,&quot;192.168.1.10&quot;,6379); Jedis jedis=null; try&#123; jedis=jedisPool.getResource(); jedis.auth(&quot;123456&quot;); jedis.set(&quot;name&quot;, &quot;Jedis Redis&quot;); String value=jedis.get(&quot;name&quot;); System.out.println(value); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125;finally&#123; if(jedis!=null)&#123; jedis.close(); &#125; if(jedisPool!=null)&#123; jedisPool.close(); &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://orzn.github.io/tags/database/"},{"name":"redis","slug":"redis","permalink":"http://orzn.github.io/tags/redis/"}]},{"title":"Java-annotation简介","slug":"java-annotation","date":"2018-06-01T12:30:01.000Z","updated":"2018-08-06T13:38:16.582Z","comments":true,"path":"2018/06/01/java-annotation/","link":"","permalink":"http://orzn.github.io/2018/06/01/java-annotation/","excerpt":"","text":"Java注解在之前的学习实践过程基本没有用过，但是今天碰到了，感觉还是有必要学习记录一下。 注解的定义注解通过@interface关键字进行定义。12public @interface TestAnnotation&#123;&#125; 这个形式和接口的定义很像，但是多了个@,上面的代码就定义了一个TestAnnotation。要想注解能够正常工作，还需要介绍一下新的概念那就是元注解。元注解是可以注解到注解上的注解，或者说元注解是一种基本注解，但是它能够应用到其它的注解上面。元注解有 @Retention、@Documented、@Target、@Inherited、@Repeatable 5 种。 @Retention@Retention 应用到一个注解上的时候，它解释说明了这个注解的的存活时间。它的取值有如下三个： RetentionPolicy.SOURCE 注解只在源码阶段保留，在编译器进行编译后就不存在了。如@Override。 RetentionPolicy.CLASS注解只被保留到编译进行的时候，它并不会被加载到JVM中。默认是clas。 RetentionPolicy.RUNTIME 注解可以保留到程序运行的时候，它会被加载进入到JVM中，所以在程序运行时可以获取到它们。 我们可以用以下两种方法指定注解：12@Retention(RetentionPolicy.RUNTIME)@Retention(value=CLASS) @Documented这个注解作用是能够将注解中的元素包含到Javadoc中去。 @Target@Target指定了注解运用的地方。 ElementType.ANNOTATION_TYPE可以给一个注解进行注解。 ElementType.CONSTRUCTOR可以给构造方法进行注解 ElementType.FIELD可以给属性进行注解 ElementType.LOCAL_VARIABLE可以给局部变量进行注解 ElementType.METHOD可以给方法进行注解 ElementType.PACKAGE可以给一个包进行注解 ElementType.PARAMETER可以给一个方法内的参数进行注解 ElementType.TYPE可以给一个类型进行注解，比如类、接口、枚举 @Inherited@Inherited表明注解类可以被继承，当类A被这样的注解修饰之后，类B继承A，则类B也拥有这个注解。接口，方法的注解不能被继承。 @Repeatable这个是Java1.8之后才有的注解。12345678910111213@interface Persons &#123; Person[] value();&#125;@Repeatable(Persons.class)@interface Person&#123; String role default &quot;&quot;;&#125;@Person(role=&quot;artist&quot;)@Person(role=&quot;coder&quot;)@Person(role=&quot;PM&quot;)public class SuperMan&#123;&#125; 上面的Persons是一个容器注解，就是用来存放其他注解，Person的地方。按规定，容器注解中必须有一个value数组，属性类型被@Repeatable注解过。之后，就可以用多个Person注解。 注解属性注解的属性也叫做成员变量。注解只有成员变量，没有方法。注解的成员变量在注解的定义中以“无形参的方法”形式来声明，其方法名定义了该成员变量的名字，其返回值定义了该成员变量的类型。123456@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface TestAnnotation &#123; int id(); String msg();&#125; 像上面的注解要进行复制，是在注解的括号内以 value=”” 形式，多个属性之前用 ，隔开。12@TestAnnotation(id=3,msg=&quot;hello annotation&quot;)public class Test &#123; &#125; 注解中的属性可以有默认值，需要用default关键字指定。如：1public int id() default -1; 如果只有一个变量，可以省略value=-1,直接在括号里赋值-1。没有属性时，括号都可以省略。 注解提取想要获知某一对象是否应用了某注解，可以用反射。首先可以通过 Class对象的isAnnotationPresent()方法判断它是否应用了某个注解。1public boolean isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass) &#123;&#125; 然后通过 getAnnotation() 方法来获取 Annotation 对象。1public &lt;A extends Annotation&gt; A getAnnotation(Class&lt;A&gt; annotationClass) &#123;&#125; 或者是 getAnnotations() 方法。1public Annotation[] getAnnotations() &#123;&#125; 完整的例子如下：12345678910111213141516@TestAnnotation()public class Test &#123; @Check(value=&quot;hi&quot;) int a; @Perform public void testMethod()&#123;&#125; public static void main(String[] args) &#123; boolean hasAnnotation = Test.class.isAnnotationPresent(TestAnnotation.class); if ( hasAnnotation ) &#123; TestAnnotation testAnnotation = Test.class.getAnnotation(TestAnnotation.class); System.out.println(&quot;id:&quot;+testAnnotation.id()); System.out.println(&quot;msg:&quot;+testAnnotation.msg()); &#125; &#125;&#125; 还可以用相同的方法获取变量，方法上的注解。1234567891011Field a = Test.class.getDeclaredField(&quot;a&quot;);a.setAccessible(true);//私有变量访问性必须设为true，才能访问。Check check = a.getAnnotation(Check.class);Method testMethod = Test.class.getDeclaredMethod(&quot;testMethod&quot;);if ( testMethod != null ) &#123; // 获取方法中的注解 Annotation[] ans = testMethod.getAnnotations(); for( int i = 0;i &lt; ans.length;i++) &#123; System.out.println(&quot;method testMethod annotation:&quot;+ans[i].annotationType().getSimpleName()); &#125;&#125; 使用场景官方文档中如是说： 提供信息给编译器：编译器可以利用注解来探测错误和警告信息。 编译阶段时的处理：软件工具可以用来利用注解信息来生成代码、Html文档或者做其它相应处理。 运行时的处理：某些注解可以在程序运行的时候接受代码的提取。具体点说，在spring中有ApplicationContext.getBeansWithAnnotation()，可以得到所有有特定注解的bean集合，方便系统参数的初始化等等。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://orzn.github.io/tags/java/"},{"name":"annotation","slug":"annotation","permalink":"http://orzn.github.io/tags/annotation/"}]},{"title":"Zookeeper初探（一）","slug":"Zookeeper-1","date":"2018-06-01T08:11:12.000Z","updated":"2018-06-02T05:18:37.760Z","comments":true,"path":"2018/06/01/Zookeeper-1/","link":"","permalink":"http://orzn.github.io/2018/06/01/Zookeeper-1/","excerpt":"","text":"概述ZooKeeper是一种分布式协调服务，其本身类似于标准文件系统。通过这个文件系统，Zookeeper提供了以下几种常见服务： 命名服务 按名称标示集群中的节点 配置管理 加入节点的最近和最新的系统配置信息 集群管理 实时的在集群和节点状态中加入/离开节点 选举算法 选举一个节点作为协调目的的leader 锁定和同步服务 在修改数据的同时锁定数据。此机制可帮助你在连接其他分布式应用程序（如Apache HBase）时进行自动故障恢复。 高度可靠的数据注册表 即使在一个或几个节点关闭时也可以获得数据。 基础系统根目录是‘/’，一个名字是一系列的以‘/’隔开的路径元素，如下图所示。 区别于标准文件系统的是，Zookeeper命名空间中的每个节点可以有数据也可以有子目录。每个节点称为znode。znode维持了一个stat结构，包括数据变化的版本号、访问控制列表变化、时间戳和数据长度。默认情况下，znode能够存储1MB的数据。每当znode的数据有变化，版本号就会增加。znode节点分为两种，永久节点和临时节点。临时节点和session存活的一样长，当session结束时，也跟着删除。在Zookeeper客户端与服务端成功完成连接创建后，就创建了一个会话。客户端以特定的时间间隔发送心跳以保持会话有效。如果ZooKeeper集合在超过服务器开启时指定的期间（会话超时）都没有从客户端接收到心跳，则它会判定客户端死机。Zookeeper支持watches的概念。客户端可以在znode上设置一个watch。当znode发生变化时触发并移除watch。当watch被触发时，客户端会接收到一个包说明znode有变化了。当连接会话过期时，客户端将与服务器断开连接，相关的watches也将被删除。 ZAB协议ZAB协议是为分布式协调服务Zookeeper专门设计的一种支持崩溃恢复的原子广播协议。基于该协议，Zookeeper实现了一种主备模式的系统架构来保持集群中各副本之间数据的一致性。具体的，是使用了一个单一的主进程来接收并处理客户端的所有事务请求，并采用ZAB的原子广播协议，将服务器数据的状态变更以事物Proposal的形式广播到所有的副本进程上去。另一方面，考虑到分布式环境中，顺序执行的一些状态变更其前后会存在一定的依赖关系，这样的依赖关系也对ZAB协议提出了一个要求，ZAB协议必须保证一个全局的变更序列被顺序应用。最后，考虑到主进程在任何时候都可能出现崩溃推出或重启现象，因此，ZAB协议还要在出现上述异常时，依旧能正常工作。其核心类似2pc协议： Leader服务器将一个客户端的请求转换成一个事务Proposal（提议），并将该事务发给集群中所有follower服务器。之后，leader服务器需要等待所有follower服务器反馈，若得到超过半数的正确反馈，leader就会再次向所有follower服务器分发commit消息，要求将前一个Proposal提交。 协议介绍ZAB协议包括两种基本的模式，崩溃恢复和消息广播。崩溃恢复指的是服务刚启动或者leader服务器出现崩溃退出时，要重新选举leader，同时集群中有超过半数的机器与leader完成了状态同步之后，退出恢复模式。具体我们分开讲： 消息广播在广播过程中，Leader服务器会为每个事务请求生成对应的Proposal来进行广播，并为其分配一个全局单调递增的唯一ID，称之为事务ID（即ZXID）。为了保证消息严格的因果关系，因此，必须将每一个事务Proposal按照ZXID的先后顺序来进行排序与处理。另外，整个消息广播协议是基于FIFO特性的TCP协议来进行网络通信的，因此能很容易地保证消息广播过程中消息接收与发送的顺序性。具体的，每个follower都有一个单独的队列，需要广播的事务就依次放入队列中，根据FIFO进行消息发送。每个follower接收到事务之后，都会首先以事务日志的形式写到磁盘中，写入成功后会给leader服务器一个ACK响应，leader收到过半数的ACK后，会通知所有follower进行事务提交，同时自身也完成事务提交。 崩溃恢复ZAB协议确保已经在leader服务器上提交的事务最终被所有服务器都提交，确保丢弃那些只在leader服务器上被提出的事务。为了满足这些，只需保证找到的新leader服务器拥有所有机器最大ZXID编号的事务Proposal。完成选举后，leader服务器得确认事务日志中的所有Proposal是否都已经被急集群中过半的机器提交了，即是否完成数据同步。我们先看下ZXID的设计，ZXID高32位表示leader周期epoch的编号，低32位代表每一个事务编号。都是依次加一。Leader服务器会为每一个follower准备一个队列，并将那些没有被follower同步的事务以Proposal消息的形式逐个发送，并紧接着发送一个commit消息。若这时，先前崩溃的尚未提交的事务Proposal机器恢复了，leader服务器会和其进行对比，要求follower进行回退。在服务器集群初始化阶段，leader选举就复杂一些。（1） 每个server发出投票，包含myid，ZXID。（2） 接收来自各个服务器的投票。ZXID大优先，若相同，myid大的优先。若接受了新的选票，就将新的选票发出去；若没有接受，则不处理。（3） 对投票信息进行统计，若超过半数的选票的机器即为leader节点。 未完待续。","categories":[],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://orzn.github.io/tags/Zookeeper/"}]},{"title":"Java-动态代理简介","slug":"java-动态代理","date":"2018-05-31T10:40:31.000Z","updated":"2018-08-06T13:37:54.189Z","comments":true,"path":"2018/05/31/java-动态代理/","link":"","permalink":"http://orzn.github.io/2018/05/31/java-动态代理/","excerpt":"","text":"代理模式是常用的Java设计模式之一，而根据创建代理类的时间点，又可以分为静态代理和动态代理。他的特征是代理类和委托类继承同样的接口，代理类本身并不真正实现服务，而是负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。 静态代理就像上图所示，程序员直接创建好所有需要的代码，也就是在编译时就已经将接口，被代理类，代理类确定下来。动态代理中的代理类并不是在Java代码中定义的，而是在运行时根据我们在Java代码中的指示动态生成的。 Java的动态代理有两种实现方法，一种是JDK动态代理，一种是CGlib。 1、JDK JDK方法实现InvocationHandler接口，用bind方法绑定实现类对象，invoke方法调用对象方法。举个例子： 先定义一个接口：123public interface BookFacade&#123; public void addBook();&#125; 然后，创建委托类，即真正的业务实现类：123456public class BookFacadeImpl implements BookFacade &#123; @Override public void addBook() &#123; System.out.println(&quot;增加图书方法。。。&quot;); &#125; &#125; 最后，创建动态代理类：12345678910111213141516public class BookFacadeProxy implements InvocationHandler&#123; private Object target;//委托类对象 public Object bind(Object target)&#123; this.target = target; //通过反射机制，创建一个代理类对象实例并返回，用户进行方法调用时使用 return Proxy.newProxyInstance(target.getClass().getClassLoader(),target.getClass().getInterfaces(), this); &#125; public Object invoke(Object proxy,Method method,Object[] args)&#123; Object result=null; System.out.println(&quot;预处理操作——————&quot;); //调用真正的业务方法 result=method.invoke(target, args); System.out.println(&quot;调用后处理——————&quot;); return result; &#125;&#125; 如何使用：123456public static void main(String[] args) &#123; BookFacadeImpl bookFacadeImpl=new BookFacadeImpl(); BookFacadeProxy proxy = new BookFacadeProxy(); BookFacade bookfacade = (BookFacade) proxy.bind(bookFacadeImpl); bookfacade.addBook(); &#125; 在代理类实现中也可以不实现bind，在main函数中执行Proxy.newProxyInstance()。这个函数的作用就是把返回的接口对象和代理类绑定在一起，当执行接口函数时，会执行代理类的invoke。 2、CGlib CGlib是针对类来实现代理的。代理类实现MethodInterceptor接口。 先定义一个类：12345public class BookFacadeImpl&#123; public void addBook()&#123; System.out.println(&quot;新增图书。。。&quot;); &#125;&#125; 然后创建代理类：1234567891011121314151617181920public class BookFacadeCglib implements MethodInterceptor &#123; private Object target;//业务类对象 //相当于JDK动态代理中的绑定 public Object getInstance(Object target) &#123; this.target = target; Enhancer enhancer = new Enhancer(); //创建加强器，用来创建动态代理类 enhancer.setSuperclass(this.target.getClass()); //为加强器指定要代理的业务类（即：为下面生成的代理类指定父类） //设置回调：对于代理类上所有方法的调用，都会调用CallBack，而Callback则需要实现intercept()方法进行拦 enhancer.setCallback(this); // 创建动态代理类对象并返回 return enhancer.create(); &#125; // 实现回调方法 public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println(&quot;预处理——————&quot;); proxy.invokeSuper(obj, args); //调用业务类（父类中）的方法 System.out.println(&quot;调用后操作——————&quot;); return null; &#125;&#125; 如何使用：123456public static void main(String[] args) &#123; BookFacadeImpl1 bookFacade=new BookFacadeImpl1()； BookFacadeCglib cglib=new BookFacadeCglib(); BookFacadeImpl1 bookCglib=(BookFacadeImpl1)cglib.getInstance(bookFacade); bookCglib.addBook(); &#125; PS: CGlib是一个代码生成包。除了动态代理，还提供了反射功能，据称效果更好。show the code.1234Class&lt;?&gt; clazz = x.getClass();FastClass fastClass = FastClass.create(clazz); //得到对象的fast类FastMethod faseMethod = fastClass.getMethod(methodName,parameterTypes);//输入参数名和参数类型。fastMethod.invoke(x,parameters);//执行x对象的方法 以上。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://orzn.github.io/tags/java/"},{"name":"动态代理","slug":"动态代理","permalink":"http://orzn.github.io/tags/动态代理/"}]},{"title":"Java-AQS简介","slug":"java AQS","date":"2018-05-31T10:39:27.000Z","updated":"2018-08-06T13:37:29.301Z","comments":true,"path":"2018/05/31/java AQS/","link":"","permalink":"http://orzn.github.io/2018/05/31/java AQS/","excerpt":"","text":"AQS，即AbstractQueuedSynchronizer。提供了一个基于FIFO队列，和state变量，可以用于构建锁或者其他相关同步装置的基础框架。目前我所了解到的ReentrantLock、ReadWriteLock，CountdownLatch，FutureTask等实现都依赖于AQS。 前面提到的FIFO队列，节点Node保存着线程引用和线程状态。表示每一个等待锁的线程。Node主要包含以下成员变量： 1234567Node&#123; int waitStatus; Node prev; Node next; Node nextWaiter; Thread thread;&#125; 下面通过一个排它锁这个例子来理解一下同步器的工作原理。其中，state初始化为0，表示排它锁可用，变为1表示排它锁被占用。 12345678910111213141516171819202122232425262728293031323334353637383940414243class Mutex implements Lock, java.io.Serializable &#123; // 内部类，自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; // 是否处于占用状态 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // 当状态为0的时候获取锁 public boolean tryAcquire(int acquires) &#123; assert acquires == 1; // Otherwise unused if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; // 释放锁，将状态设置为0 protected boolean tryRelease(int releases) &#123; assert releases == 1; // Otherwise unused if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; // 返回一个Condition，每个condition都包含了一个condition队列 Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; // 仅需要将操作代理到Sync上即可 private final Sync sync = new Sync(); public void lock() &#123; sync.acquire(1); &#125; public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125; public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125; public boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; &#125; 若自己要实现同步，可像上面代码一样新建内部类Sync，继承自AQS并按需实现钩子方法。（钩子方法源于设计模式中模板方法模式，模板方法模式中分为两大类：模版方法和基本方法，而基本方法又分为：抽象方法，具体方法，钩子方法。钩子方法的实际应用为，对于一个接口，而你只想使用接口中的一个方法，那么你可以写一个抽象类实现这个接口，将那个方法设置为abstract，其它方法进行空实现，然后你再继承这个抽象类，就不需要实现其它的方法。）钩子方法 | 简介 | :-:tryAcquire (int arg) | 排他获取(资源数)tryRelease(int arg) | 排他释放(资源数)tryAcquireShared(int arg)tryAcquireShared(int arg) | 共享获取(资源数)tryReleaseShared(int arg) | 共享释放(资源数)isHeldExclusively() | 是否排他状态 方法不需要全部实现，如果像排它锁那样的，只需实现排他方法。AQS的其他方法可以直接继承使用。 那么，现在设计一个同步工具，该工具在同一时刻只能有两个线程能够并发访问，超过限制的其他线程进入阻塞状态。因为要共享资源，所以需要实现tryAcquireShared和tryReleaseShared方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class TwinsLock implements Lock &#123; private final Sync sync = new Sync(2); private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -7889272986162341211L; Sync(int count) &#123; if (count &lt;= 0) &#123; throw new IllegalArgumentException(&quot;count must large than zero.&quot;); &#125; setState(count);//设置初始state &#125; public int tryAcquireShared(int reduceCount) &#123; for (;;) &#123; int current = getState(); int newCount = current - reduceCount; //等于-1直接就无法获取锁 if (newCount &lt; 0 || compareAndSetState(current, newCount)) &#123; return newCount; &#125; &#125; &#125; public boolean tryReleaseShared(int returnCount) &#123; for (;;) &#123; int current = getState(); int newCount = current + returnCount; if (compareAndSetState(current, newCount)) &#123; return true; &#125; &#125; &#125; &#125; public void lock() &#123; sync.acquireShared(1); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; public boolean tryLock() &#123; return sync.tryAcquireShared(1) &gt;= 0; &#125; public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(time)); &#125; public void unlock() &#123; sync.releaseShared(1); &#125; @Override public Condition newCondition() &#123; return null; &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://orzn.github.io/tags/java/"},{"name":"AQS","slug":"AQS","permalink":"http://orzn.github.io/tags/AQS/"}]},{"title":"synchronized详解","slug":"多线程-synchronized","date":"2018-04-21T06:30:10.000Z","updated":"2018-08-01T15:34:54.071Z","comments":true,"path":"2018/04/21/多线程-synchronized/","link":"","permalink":"http://orzn.github.io/2018/04/21/多线程-synchronized/","excerpt":"","text":"synchronized是java里一个重要的关键词。当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。 基本功能 同步一个代码块:12345public void func()&#123; synchronized(this)&#123; ... &#125;&#125; 它只作用于一个对象this，所以不同的对象的方法func不会同步。 同步一个方法：12public synchronized void func()&#123;&#125; 这个和上面的例子一样。 同步一个类：1234public void func()&#123; synchronized(synchronizedExample.class)&#123; &#125;&#125; 上面的synchronized作用于整个类，所以两个线程调用同一个类的不同对象上的函数，也会进行同步。123public synchronized static void fun()&#123; ...&#125; 和上面一样。 原理和优化 我们需要先了解在JVM中，对象是怎么存的。对象存储时分成3部分，对象头、实例数据和对齐填充。实例数据存储的是类的属性数据信息，父类信息，如果是数组还包括数组的长度。对齐填充就是为了字节对齐而产生的。而对象头是sync里要用到的重要结构。对象头主要分为两部分，Mark Word和Class Metadata Address。Mark Word存储对象的hashCode、锁信息或分代年龄或GC标志等信息。Class Metadata Address很明显，存的是指针，指向对象的类元数据，用来确定对象属于什么类。sync通过Mark Word来实现轻量级锁，偏向锁等优化。 每一个对象都存在着一个monitor与之关联，monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，HotSpot虚拟机中，这部分代码是由C++实现的。每个试图获取锁的线程会进入EntryList，得到锁时，monitor中的owner变量设为当前线程，若线程调用wait()时，owner变null，线程进入waitSet队列中等待被唤醒。monitor依赖于底层操作系统的Mutex Lock，线程之间切换时需要从用户态转换到和心态，因此效率低。Java6之后，引入了轻量级锁和偏向锁。 偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。 偏向锁对象只在第一次被拥有时，记录下偏向线程ID，退出同步也不需去锁，之后每次同步都只用检查ID。如果不一致，则锁膨胀为轻量级锁。 轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。轻量级锁采用CAS获取锁（在当前栈帧中建立Lock Record存储锁对象的Mark Word，再使用CAS将锁对象的Mark Word指向Lock Record），若发现自己已拥有锁，则计入同步块继续执行，否则就自旋来获取锁。每次退出同步块都要释放锁，也尝试CAS把Lock Record记录替换回锁对象头。若失败，则膨胀。 和ReentrantLock对比 锁的实现：syn是JVM实现的，而Lock是JDK实现的。 性能：早期Lock效率更高，现在Java对syn进行了很多优化，如自旋锁等，二者效率大致相当。 等待可中断：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理的其他事情。ReentrantLock可中断，而syn不行。 公平锁：syn中锁是非公平的，而ReentrantLock默认情况下也是非公平的，但是也可以是公平的。 锁绑定多个条件：一个ReentrantLock可以同时绑定多个Condition对象。ps:除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是JVM实现的一种锁机制，JVM原生地支持它，而ReentrantLock不是所有的JDK版本都支持。并且使用synchronized不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。","categories":[],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://orzn.github.io/tags/多线程/"},{"name":"synchronized","slug":"synchronized","permalink":"http://orzn.github.io/tags/synchronized/"}]},{"title":"java线程池的使用","slug":"java-线程池","date":"2018-03-15T11:38:10.000Z","updated":"2018-07-21T10:45:23.799Z","comments":true,"path":"2018/03/15/java-线程池/","link":"","permalink":"http://orzn.github.io/2018/03/15/java-线程池/","excerpt":"","text":"java线程的创建销毁会大大降低系统效率，因此，线程池便应用而生。线程得以复用，执行完一个任务后，继续执行其他任务。而在Java中构建的线程池的类，就是ThreadPoolExecutor。 ThreadPoolExecutor ThreadPoolExecutor继承了抽象类AbstractExecutorService。而这个抽象类实现了ExecutorService接口，这个接口继承了Executor接口，这个顶层的接口声明了execute方法。这个方法也是线程池执行任务的方法。ThreadPoolExecutor提供了四种构造方法，如下：123456789101112131415public class ThreadPoolExecutor extends AbstractExecutorService &#123; ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ...&#125; 而前三个方法实际上都是调用的第四个方法，让我们看一下里面的主要参数： corePoolSize：核心池大小 maximumPoolSize：线程池最大线程数 keepAliveTime：非核心线程没有任务执行时存活时间。但如果调用了allowCoreThreadTimeOut(boolean)方法，参数也会对核心池起作用。 unit：keepAliveTime的单位，有TimeUnit.HOURS，TimeUnit.MINUTES等。 workQueue：一个阻塞队列，存储等待执行的任务。 threadFactory：线程工厂，可以写个初始化线程方法。 handler：拒绝处理任务时的策略。 七七八八 那么具体执行时，若当前线程池的线程数目小于corePoolSize,则每来一个任务，就会创建线程去执行。若当前线程池中数目&gt;=corePoolSize，则来的任务会先放入空闲队列，若满了，就建非核心线程执行。若线程池线程数达到maximumPoolSize，则采用任务拒绝策略处理。workQueue，通常有如下三种： ArrayBlockingQueue：基于数组的先进先出队列，创建时必须指定大小。 LinkedBlockingQueue：基于链表的先进先出队列，创建时若没指定大小，则默认为Integer.MAX_VALUE。 synchronousQueue：不会保存任务，而是直接新建线程执行。 handler，有如下四种： ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 一般我们不需要自己使用ThreadPoolExecutor，而使用Executors类提供的静态方法去创建。123456789public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService(new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;//通常用于执行一些生存期很短的异步型任务 对于线程池大小的设置有个一般经验，对于CPU密集型任务，可以设成CPU+1。若是IO密集型，可设为2*CPU。","categories":[],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://orzn.github.io/tags/多线程/"},{"name":"线程池","slug":"线程池","permalink":"http://orzn.github.io/tags/线程池/"}]},{"title":"ThreadLocal简介","slug":"多线程-ThreadLocal","date":"2018-03-15T11:38:10.000Z","updated":"2018-07-21T17:56:11.767Z","comments":true,"path":"2018/03/15/多线程-ThreadLocal/","link":"","permalink":"http://orzn.github.io/2018/03/15/多线程-ThreadLocal/","excerpt":"","text":"ThreadLocal，是为每个线程保存一份局部变量的存在。具体的内部构造方法，网上有很多其实描述的不是很准确，故特此记录。先看下ThreadLocal中的主要函数:123456789101112131415161718192021222324 void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 可以看出，数据是存放在ThreadLocalMap中，key可看作是ThreadLocal的弱引用。ThreadLocalMap是ThreadLocal的内部类。每一个Thread类中也有个ThreadLocalMap类型变量，而每个线程都会有自己的ThreadLocalMap，因此不是说共用一个Map，靠线程做key进行区分。若程序中有ThreadlLocal&lt;A&gt; Xa，ThreadLocal&lt;B&gt; Xb，则每个Thread类的ThreadlocalMap则会存储A、B两类的数据，且key分别为Xa，Xb。那么，在看下ThreadLocalMap类，这个类也像普通的map类一样，含有初始大小，负载因子等，这个就不多说了，关键看一下弱引用的作用。12345678910111213static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private Entry[] table; ... 在Java里，含有强引用，软引用，弱引用，虚引用四种类型。其中，强引用就是平时接触最多的类型，A a = new A()，a就是强引用；软引用就是空间不足时，无论是否有引用都可以被回收；弱引用是每次垃圾回收时都回收；软引用，弱引用都可以单独使用，而虚引用不能单独使用，有和没有引用一样，就是用来跟踪对象被垃圾回收的状态。 从代码中，看到map中存的是entry数组，实际中根据Threadlocal取值时，还要经过一番hashCode计算，这里也不再详述。就看作Threadlocal是key，那么，对象的引用关系就如下图： 为什么要用弱引用？首先来说，如果把ThreadLocal置为null，那么意味着Heap中的ThreadLocal实例不在有强引用指向，只有弱引用存在，因此GC是可以回收这部分空间的，也就是key是可以回收的。但是value却存在一条从Current Thread过来的强引用链。因此只有当Current Thread销毁时，value才能得到释放。 事实上，在ThreadLocalMap中的set/getEntry方法中，会对key为null（也即是ThreadLocal为null）进行判断，如果为null的话，那么是会对value置为null的。因此，当Threadlocal设为null之后，就能比较便利的清理内存空间。","categories":[],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://orzn.github.io/tags/多线程/"},{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://orzn.github.io/tags/ThreadLocal/"}]},{"title":"聊聊字典树","slug":"字典树-数据结构","date":"2018-03-14T06:40:45.000Z","updated":"2018-07-15T06:59:47.170Z","comments":true,"path":"2018/03/14/字典树-数据结构/","link":"","permalink":"http://orzn.github.io/2018/03/14/字典树-数据结构/","excerpt":"","text":"字典树，又称trie树，单词查找树。是一种哈希树的变种。那么这里，就不得不先提一下什么是哈希树。 哈希树 我们知道通常要进行哈希操作，肯定会发生碰撞，而哈希树算法就是要提供一种在理论上和实际应用总均能有效地处理冲突的方法。一般的哈希算法是用空间换时间，而哈希树则采用了一种技巧使得对空间的需求控制在一定范围内。 质数分辨定理 简单地说就是：n个不同的质数可以“分辨”的连续整数的个数和他们的乘积相等。“分辨”就是指这些连续的整数不可能有完全相同的余数序列。即对于3,5两个质数来说，可以分辨15个数。连续10个质数就可以分辨大约M(10) =23571113171923*29= 6464693230 个数。这已经足够满足人们的需求。 建树 选择从2开始的连续质数来建立一个十层的哈希树，第一层结点为根节点，根节点下有两个结点，表示除2的余数为0或1，第二层的每个节点下有3个节点，表示除以3的余数为0,1,2。123456struct Node&#123; keyType key; ValueType value; bool occupied; struct Node* subNode[1];&#125; 哈希树的节点结构如上所示，occupied表示该节点是否存有数。在在建树的过程中，不需要直接把每一层的空间事先开辟出来，可以等发生冲突在建立新的节点。具体流程，看图就明白了。 查找 哈希树的查找过程和节点插入类似，就是除数取余，直至找到最终节点。可以很快的判断某个数是否存在。而删除节点也很简单，就把那个节点的ocuppied给标记为false就行。 字典树 看完哈希树，再说字典树就很简单了。哈希树里面存的是哈希值，字典树里存的就是单词字母了。每一层节点都有26个子节点，表示a,b,c,…,z。从根节点到目标节点的路径上的词串起来就是想要存的单词。其典型应用是统计，排序和保存大量的字符串，经常被用作文本词频统计。talk is cheap, show you the code.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class TrieNode &#123; boolean isLeaf; Map&lt;Character,TrieNode&gt; content; // Initialize your data structure here. public TrieNode() &#123; content = new HashMap&lt;Character,TrieNode&gt;(); &#125;&#125;public class Trie &#123; private TrieNode root; public Trie() &#123; root = new TrieNode(); &#125; // Inserts a word into the trie. public void insert(String word) &#123; if(word == null || word.length() == 0)&#123; return; &#125; TrieNode node = root; TrieNode tempNode = null;; for(int i=0, len=word.length(); i&lt;len; i++)&#123; Character c = word.charAt(i); tempNode = node.content.get(c); if(tempNode == null)&#123; tempNode = new TrieNode(); node.content.put(c,tempNode); &#125; node = tempNode; &#125; node.isLeaf = true; &#125; // Returns if the word is in the trie. public boolean search(String word) &#123; if(word == null || word.length() == 0)&#123; return false; &#125; TrieNode node = root; TrieNode tempNode = null;; for(int i=0, len=word.length(); i&lt;len; i++)&#123; Character c = word.charAt(i); tempNode = node.content.get(c); if(tempNode == null)&#123; return false; &#125; node = tempNode; &#125; return node.isLeaf; &#125; // Returns if there is any word in the trie // that starts with the given prefix. public boolean startsWith(String prefix) &#123; if(prefix == null || prefix.length() == 0)&#123; return false; &#125; TrieNode node = root; TrieNode tempNode = null;; for(int i=0, len=prefix.length(); i&lt;len; i++)&#123; Character c = prefix.charAt(i); tempNode = node.content.get(c); if(tempNode == null)&#123; return false; &#125; node = tempNode; &#125; return true; &#125;&#125;","categories":[],"tags":[{"name":"字典树， 数据结构","slug":"字典树，-数据结构","permalink":"http://orzn.github.io/tags/字典树，-数据结构/"}]},{"title":"聊聊红黑树","slug":"红黑树-数据结构","date":"2018-03-14T06:40:45.000Z","updated":"2018-07-15T11:19:33.928Z","comments":true,"path":"2018/03/14/红黑树-数据结构/","link":"","permalink":"http://orzn.github.io/2018/03/14/红黑树-数据结构/","excerpt":"","text":"红黑树是一个平衡的二叉树，但是不是常说的那个平衡二叉树，左右高度相差小于等于１。红黑树放宽了条件，但能在对数时间内完成查找删除。红黑树需要满足五个性质： 节点是红色或者黑色。 根节点是黑色。 每个叶节点（空节点）是黑色。 每个红色节点的两个子节点都是黑色的（也就是说不存在两个连续的红色节点）。 从任一节点到每个叶节点所有路径都包含相同数目的黑色节点。 为什么说红黑树能在对数时间内完成基本操作呢？首先来说为什么红黑树的高度是lgN（N是节点数）。先设从某节点x出发，到叶节点的路径上黑色节点的个数称为黑高度，记为bh(x)。首先用数学归纳法可以证明：以结点x为根的子树中至少包含2^bh(x) -1个内结点。其次，假设红黑树的高度为h（根结点的高度为0），由性质④可知：从根结点(不包括根)到叶结点的任一简单路径上至少有一半的结点是黑色的，从而根的黑高度至少是 h/2。再根据上面数学归纳法的结论：红黑树的根结点的子树中至少包含 2^h/2-1 个内结点。从而有： n &gt;= 2^h/2 -1， 得出 h &lt;= 2log(n+1)，从而证明了红黑树的高度是O(logN)。 这里我不想提红黑树的具体插入删除，而想聊一下hashmap与红黑树。直接看hashmap的put方法。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //table为空就创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //确定插入table的位置，算法是(n - 1) &amp; hash if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //在table的i位置发生碰撞，有两种情况，1、key值是一样的，替换value值， //2、key值不一样的有两种处理方式：2.1、存储在i位置的链表；2.2、存储在红黑树中 else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //2.2 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //2.1 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //超过了链表的设置长度8就扩容 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //如果e为空就替换旧的oldValue值 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //threshold=newThr:(int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); //默认0.75*16，大于threshold值就扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 下面说说hash的算法和寻址的算法1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 哈希将高16位和低16位的结果进行异或，可以减少碰撞。因为不这么做，直接hash&amp;(n-1)（ps:数组长度因为是2的幂数，减1后面二进制都是1，与的结果相当于hash的后几位%（n-1），这样更高效），但这样，就只考虑了低几位的结果，故容易发生碰撞。然后是链表转红黑树的代码12345678910111213141516171819202122final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; //当tab.length&lt;MIN_TREEIFY_CAPACITY(64)是还是进行resize if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) //存储在红黑树 hd.treeify(tab); &#125; &#125; 可看到，即使链表长度超过8，总数小于64还是会先扩容。resize()之后，很明显，有些点会在原位置，有些会移动2次幂的位置。为什么这么说，因为你想，每次扩容之后，实际就是计算hash&amp;（n-1）的时候，多了一位。而我们只用看hash值对应的那位是1还是0,如果是0就不变，是1就移动原位置+2次幂的值。所以，扩容的时候，需要重新计算hash，只要看1位就行。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order //分别记录头和尾的节点 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; //把节点移动新的位置j+oldCap,这种情况不适用与链表的节点数大于8的情况 //链表节点大于8的情况会转换为红黑树存储 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 最后，是转为红黑树的具体代码12345678910111213141516171819202122232425262728293031323334353637383940414243final void treeify(Node&lt;K,V&gt;[] tab) &#123; TreeNode&lt;K,V&gt; root = null; for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (root == null) &#123; x.parent = null; x.red = false; root = x; &#125; else &#123; K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; //遍历root，把节点x插入到红黑树中，执行先插入，然后进行红黑树修正 for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk);//比较k和pk的值，用于判断是遍历左子树还是右子树 TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; //修正红黑树 root = balanceInsertion(root, x); //退出循环 break; &#125; &#125; &#125; &#125; moveRootToFront(tab, root); &#125; ps:当红黑树长度小于6时，会退成链表形式。","categories":[],"tags":[{"name":"红黑树， 数据结构","slug":"红黑树，-数据结构","permalink":"http://orzn.github.io/tags/红黑树，-数据结构/"}]},{"title":"vmware tools失效","slug":"vmware","date":"2017-12-27T12:37:22.000Z","updated":"2018-05-31T16:42:59.139Z","comments":true,"path":"2017/12/27/vmware/","link":"","permalink":"http://orzn.github.io/2017/12/27/vmware/","excerpt":"","text":"不知道是因为安装了哪些东西，vmware的vmware tools突然不能用了，窗口不能自适应，也不能拖动文件进行复制。折腾了好久，open-vm-tools，vmware中的vmware-tools各种反复安装，也没卵用。后来，试了别人博客一种方法，总算成功了。ps：vmware版本10，ubuntu 是16.04。 sudo apt-get autoremove open-vm-tools Install VMware Tools by following the usual method (Virtual Machine –&gt; Reinstall VMWare Tools) Reboot the VM sudo apt-get install open-vm-tools-desktop Reboot the VM, after the reboot copy/paste and drag/drop will work!","categories":[],"tags":[{"name":"vmware","slug":"vmware","permalink":"http://orzn.github.io/tags/vmware/"}]},{"title":"javaFX初探","slug":"javaFX-1","date":"2017-08-25T08:39:07.752Z","updated":"2018-05-12T17:10:54.494Z","comments":true,"path":"2017/08/25/javaFX-1/","link":"","permalink":"http://orzn.github.io/2017/08/25/javaFX-1/","excerpt":"","text":"JavaFX是Java的下一代图形用户界面工具包。JavaFX是一组图形和媒体API，我们可以用它们来创建和部署富客户端应用程序。虽说似乎是一种衰落的丰富互联网应用技术。但是因为一些原因，前段时间要写个界面，又因为最近java搞得比较多，就打算用java撸一个出来，特此做个记录。 除了javaFX，还有swing，不过相比javaFX，swing似乎更out一些。好像很久都没更新了。 开始步入正题 开发环境配置 从Java8开始，JDK(Java开发工具包)包括了JavaFX库。因此，要运行JavaFX应用程序，您只需要在系统中安装Java8或更高版本。除此之外，IDE(如Eclipse，NetBeans和idea)为JavaFX提供支持。 为IDE配置环境，我用的idea。Eclipse和NetBeans的在百度吧，这个还是挺好找的。首先，你需要下一个JavaFX Scene Builder。这是一种可视布局工具，就是一拖控件的。不要也行，但是作为一小白，还是用吧。之后，在idea中新建一个javaFX工程，创建完之后。 按上图操作，就可以在IDE中随时打开JavaFX Scene Builder，从而更方便的编辑自己的界面。 快速入门 本部分介绍如何写程序。实际创建工程完之后，会生成一个空的helloworld。里面包含三个文件：一个Main.java,一个Controller.java，一个sample.fxml。简单的说是这样，fxml定义界面外观，Controller定义操作时调用的函数，Main毫无疑问，程序的入口，加载下fxml。不过，实际上，也可以不用fxml,完全在main中写界面，但这就麻烦了。 fxml 从fxml名字就能看出，这和html很像。html是定义内容，css定义样式。在javaFX中，也可以使用css。不过，我没有用，也不是很了解。用fxml定义样式，首先要选择各种容器，我觉得这个起到的作用类似于div，之后再在里面放入各种组件。如果要对某一组件操作，比如点击后要调用某函数，需要给它定义id。 controller controller其实比较简单，就是普通的java程序。不过需要注意的是，在里面要用到的组件，需要在前面定义一下，变量名就是id名。例如： 12@FXMLprivate Label help; FXML必须写。 main main函数其实不需要怎么动。 1234567Parent root = FXMLLoader.load(getClass().getResource(&quot;sample.fxml&quot;)); primaryStage.setTitle(&quot;Hello World&quot;); primaryStage.setScene(new Scene(root, 300, 275)); primaryStage.setResizable(false); Image image= new Image(this.getClass().getResource(&quot;icon.jpg&quot;).toString(), 100, 150, false, false); primaryStage.getIcons().add(image); primaryStage.show(); 可能会用到的常见的有两个，一个是第四行的函数来保证界面大小固定，第五行，第六行的代码是改程序的图标。 最后，是给程序打包成exe。这个可折腾了我好一会儿。首先，先打成jar包，还要把Available elements中的东西都移到output root下，里面还要写Application class，后面的要与这个一致。把jar包转成exe用到的是jdk中自带的javafxpackager。 javafxpackager -deploy -appclass Test -native image -srcdir archive -outdir deploy -outfile Test 需要改的就一个Test,和输入文件、输出文件。Test是前面输入的Application class，输入文件是jar所在位置，输出就随意了。 以上是对javaFX的一个基本介绍。","categories":[],"tags":[{"name":"javaFX","slug":"javaFX","permalink":"http://orzn.github.io/tags/javaFX/"}]},{"title":"七周七并发之函数式编程","slug":"七周七并发之二","date":"2017-08-20T14:10:20.000Z","updated":"2018-05-13T07:12:49.932Z","comments":true,"path":"2017/08/20/七周七并发之二/","link":"","permalink":"http://orzn.github.io/2017/08/20/七周七并发之二/","excerpt":"","text":"提到函数式编程，就要提到命令式编程。常见的C，Java都是命令式编程，代码由一些列改变全局状态的语句过程，而函数式编程则是将计算过程抽象成表达式求值。轮子哥是这么形容函数式语言的，“函数式语言都倾向于让你用函数来组成函数，而不是把函数看成是一个数据弄成另一个数据的过程。”函数式编程可以更容易做到线程安全，因此特别适合于并发编程。 1、抛弃可变状态 函数式编程里，没有可变状态。为了体验函数式编程，这里介绍下Clojure。Clojure是一种运行在Java平台上的 Lisp 方言，Lisp是一种以表达性和功能强大著称的编程语言，但人们通常认为它不太适合应用于一般情况，而Clojure的出现彻底改变了这一现状。如今，在任何具备 Java 虚拟机的地方，您都可以利用 Lisp 的强大功能。 Clojure代码由s-表达式过构成。可以将表达式视为带括号的列表。主流语言中的max(3,5)在Clojure中写作： 1user=&gt; (max 3 5) 数学运算符也是同样的表示方式。比如1+2*3，写成： 1user=&gt; (+ 1 (* 2 3)) 使用def可以定义常量： 1234user=&gt; (def meaning-of-life 42)#&apos;user/meaning-of-lifeuser=&gt; meaning-of-life42 控制结构也可以写成s-表达式： 12user=&gt; (if (&lt; meaning-of-life 0) &quot;negative&quot; &quot;non-negative&quot;)&quot;non-negative&quot; Clojure的大多数语句都是一个s-表达式，然而也有个别例外。矢量（数组）是用方括号表示： 12345678user=&gt; (def droids [&quot;a&quot; &quot;b&quot; &quot;c&quot;])#&apos;user/droidsuser=&gt; (count droids)3user=&gt; (droids 0)&quot;a&quot;user=&gt; (droids 2)&quot;c&quot; map是用花括号表示： 1234user=&gt; (def me &#123;:name &quot;Paul&quot; :age 45 :sex :male&#125;)#&apos;user/meuser=&gt; (:age me)45 使用defn可以定义函数，函数参数是矢量形式的： 1234user=&gt; (defn percentage [x p] (* x (/ p 100.0)))#&apos;user/percentageuser=&gt; (percentage 200 10)20.0 举个例子——词频统计 先给出代码： 12345(defn word-frequencies [words](reduce (fn [counts word] (assoc counts word (inc (get counts word 0))))&#123;&#125; words)) defn定义一个函数，所有外面有一个大括号，words是参数，里面的()就是函数体，reduce是Clojure中一个函数，需要三个参数，第一个也就是fn是匿名化简函数，{}是初始值，words是集合。reduce将为集合中的每一个元素都调用一次化简函数。接着，我们看fn函数，需要两个参数counts和word，counts是一个map，(get counts word 0)返回counts中word对应的个数，inc()接受这个值并加1，assoc()更新counts中word的值。这个就是简单的词频统计，下一步是将其与XML结合，统计其中词频。 话不多说，还是直接上代码。 123(defn get-words [text] (re-seq #&quot;\\w+&quot; text))(defn count-words-sequential [pages](frequencies (mapcat get-words pages))) get-words函数是利用正则表达式将text切割成词的序列。对一个字符串序列进行映射，会得到一个二维序列。要得到一维序列，这就是mapcat的功能。 值得注意的是，Clojure中序列是懒惰的，也就是说只有在当使用时，元素才会被求值。所以，在面对大数据量，如40GB大小的文件，也完全可以处理。 2、函数式并行 map函数，接受一个函数f和一个序列，返回一个新的序列，将序列中的每一个元素的值作为f的参数，f的返回值则成新序列的对应元素。partial函数，接受一个函数和若干参数，返回一个被局部代入的函数。如：(partial * 2) 2 等于4。而Clojure中提供了功能类似于map的pmap函数，将处理过程并行化。merge-with函数将maps中其余的map合并到第一个map中。 show you the code: 12(defn count-words-parallel [pages](reduce (partial merge-with +) (pmap #(frequencies (get-words %)) pages))) note: #(frequencies (get-words %)) 等价于 (fn [page] (frequencies (get-words page))) 但是，通过实验，这里的效率提升其实并不理想。我们可以注意到，这里reduce将对每一页都调用一次合并函数，而这样计数与合并将导致大量开销。所以，可以采用批处理操作，一次处理100页。partition-all函数就提供了这样的功能，将序列中的元素分批，构成多个序列。改进后的代码如下： 1(defn count-words [pages] (reduce (partial merge-with +) (pmap count-words-sequential (partition-all 100 pages)))) 另外，补充一点，Clojure中有个fold函数实现了二分算法，可以将分组结果两两化简，直到剩下一个最终的结果。 3、函数式并发 在Java等命令式语言中，一般来说，求值顺序与其在代码中的顺序基本是一致的。但函数式语言如何安排求值顺序则是相对自由的。 在纯粹的函数式语言中，函数都具有引用透明性————在任何调用函数的地方，都可以用函数运行的结果来替代函数的调用，而不会对程序产生副作用。考虑下面这个代码，(+ 1 2)和(+ 3 4)的计算顺序与结果没有关系，完全可以同时执行。这种执行方式称为数据流式编程，Clojure提供了future模型和promise模型来支持这种执行方式。 1(+ (+ 1 2) (+ 3 4)) Future模型 future就要提到future函数，future接受一段代码，并在一个单独的线程中执行，并返回一个对象，可以用deref或@来获取对象的值。对future对象解引用时，将阻塞当前线程，直到其代表的值变得可用。所以，前面求和的代码就变成这样： 1user=&gt; (let [a (future (+ 1 2)) b (future (+ 3 4))] (+ @a @b)) let将求和结果赋值给a,b，然后求和。 Promise模型 promise模型也类似。但是使用promise对象的代码不会立即执行，直到其被赋值。 1234567user=&gt; (def life (promise))#&apos;user/lifeuser=&gt; (future (println &quot;The meaning of life is:&quot; @life))#&lt;core$future_call$reify_6110@224e59d9: :pending&gt;user=&gt; (deliver life 27)#&lt;core$promise$reify_6153@52c9f3c7: 27&gt;The meaning of life is: 27 其中，利用future函数创建线程是Clojure的惯例。 在Java8中，利用有名的lambda表达式和stream API可以写出函数式代码。 以上。","categories":[],"tags":[{"name":"七周七并发","slug":"七周七并发","permalink":"http://orzn.github.io/tags/七周七并发/"}]},{"title":"七周七并发之线程与锁","slug":"七周七并发之一","date":"2017-08-17T15:39:27.000Z","updated":"2017-08-22T12:13:21.436Z","comments":true,"path":"2017/08/17/七周七并发之一/","link":"","permalink":"http://orzn.github.io/2017/08/17/七周七并发之一/","excerpt":"","text":"线程与锁模型其实是对底层硬件运行过程的形式化。这种形式化既是该模型最大的优点也是它最大的缺点。 1、 互斥和内存模型 Java中，并发的基本单元是线程，可以将线程看作控制流。线程共享内存进行通信。线程的helloword版需要包括： 1234mythread.start();Thread.yield();System.out.println(\"hello world!\");mythread.join(); yield()的作用是通知调度器：当前线程想要让出对处理器的占用。如果不调用，则syso则几乎肯定会先执行。join()的作用是等待mythread线程执行完。当有多个线程对同一资源竞争时，解决方案就是进行同步（synchronize）访问。一种方法就是使用java的内置锁（也称为互斥锁、管城或临界区）。比如，我们要竞争的是一个函数increment()，那么在定义这个函数的时候就需要这样定义：1public synchronized void increment() &#123; ++count; &#125; 值得注意的是，线程执行过程中完全可能出现乱序执行。包括编译器的静态优化，JVM的动态优化，硬件的优化。这一部分有待进一步了解。随着近几年运行效率的提升，尤其是共享内存架构的运行效率提升，都仰仗于此类代码优化。显然，需要有明确的标准告诉我们，这就是Java内存模型。 Java内存模型定义了何时一个线程对内存的修改对另一个线程可见。基本原则是，如果读线程和写线程不进行同步，就不能保证可见性。 对共享变量的所有访问都需要同步化； 读写线程都需要同步化； 按照约定顺序来获取多把锁； 持有锁时避免调用外星方法； 持有锁的时间应尽可能短。 2、 超越内置锁 Java的内置锁是过去很长时间内，Java对并发编程提供的全部支持。Java5之后引入了java.util.concurrent包改善了这种状况，今天我们将学习这种增强的锁机制。 ReentrantLock提供了显示的lock和unlock方法。基本使用方法如下： 1234567Lock lock = new ReentrantLock();lock.lock();try&#123; //使用共享资源&#125;finally&#123; lock.unlock();&#125; ReentrantLock的好处之一就是可中断。当内置锁因争抢资源而死锁时，可用ReentrantLock的lockInterruptibly()方法。这里先留个坑。 ReentrantLock的好处之二就是设置超时时间。tryLock()提供了这个功能，在获取锁失败时有超时机制。 ReentrantLock的好处之三就是交替锁。对于一链表，当想插入一节点时，将两边两个节点锁住，然后插入。 ReentrantLock的好处之四就是条件变量。一个条件变量需要与一把锁关联，线程在开始等待条件前必须获取这把锁。获取锁后，检查所等待条件或否已经为真。如果条件为真，线程将解锁并继续执行；如果条件不为真，线程会调用await(),它将原子的解锁并阻塞等待该条件。 ReentrantLock的好处之四就是原子变量。举个栗子： 12final AtomicInteger counter = new AtomicInteger();counter.incrementAndGet(); 这里调用incrementAndGet函数，就不用担心getCount()时，忘了同步而引发的Counter内存可见性问题。其次，没有锁的参与，对原子变量的操作不会引发死锁。 3、 concurrent包 concurrent包提供了一些比内置锁更好的锁，更通用、高效、bug少的并发数据结构和工具。 123456int threadPoolSize = Runtime.getRuntime.availableProcessors()*2;ExecutorService executor = Executors.newFixedThreadPool();while(true)&#123; Socket socket = server.accept(); executor.execute(new ConnectionHandler(socket));&#125; 上面的代码，创建一个线程池，线程池的大小可以设为处理器数的两倍，如果同一时间有超过线程池大小的execute()请求存在，超出的部分将进行排队直到某线程被释放。这样，不必为每个连接都消耗资源来创建线程。影响线程池最优大小的因素有很多，但也存在经验法则，对于CPU密集型的任务，线程池大小应接近于可用核数；对于IO密集型的任务，线程池可以设置得更大。 举个例子——词频统计 词频统计需要完成了这两个任务，解析XML并构造一个Page，然后“消费”这个page，对page中的内容统计词频。这种问题，就可以归为——生产者-消费者模式。 生产者 12345678910111213class Parser implements Runnable&#123; private BlockingQueue&lt;Page&gt; queue; public Parser(BlockingQueue&lt;Page&gt; queue)&#123; this.queue = queue; &#125; public void run()&#123; try&#123; Iterable&lt;Page&gt; pages = new Pages(100000, &quot;enwiki.xml&quot;); for(Page page: pages) queue.put(page); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 消费者 1234567891011121314151617181920class Counter implements Runnable&#123; private BlockingQueue&lt;Page&gt; queue; private Map&lt;String,Integer&gt; counts; public Parser(BlockingQueue&lt;Page&gt; queue,Map&lt;String,Integer&gt; counts)&#123; this.queue = queue; this.counts = counts; &#125; public void run()&#123; try&#123; while(true)&#123; Page page = queue.take(); if(page.isPoisonPill()) break; Iterable&lt;String&gt; words = new Words(page.getText()); for(String word:words) countWord(word); &#125; &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 主程序如下： 12345678910ArrayBlockingQueue&lt;Page&gt; queue = new ArrayBlockingQueue&lt;Page&gt;(100);HashMap&lt;String,Integer&gt; counts = new HashMap&lt;String,Integer&gt;();Thread counter = new Thread(new Counter(queue,counts));Thread parser = new Thread(new Parser(queue));counter.start();parser.start();parser.join();queue.put(new PoisonPill());counter.join(); 使用concurrent包就很方便，像ArrayBlockingQueue就是中间提供的一种并发队列，提供了高效的并发方法put和take，细节就不用管。使用阻塞队列是为了防止生产者生产速度过快，消费者跟不上。 以上。","categories":[],"tags":[{"name":"七周七并发","slug":"七周七并发","permalink":"http://orzn.github.io/tags/七周七并发/"}]},{"title":"Java ConcurrentModificationException","slug":"java","date":"2017-05-18T14:26:32.003Z","updated":"2017-05-18T16:31:33.599Z","comments":true,"path":"2017/05/18/java/","link":"","permalink":"http://orzn.github.io/2017/05/18/java/","excerpt":"","text":"1. 出现原因 具体源码就不剖析了，直接说结果。原因是调用list.remove()方法导致modCount和expectedModCount的值不一致。注意，像使用for-each进行迭代实际上也会出现这种问题。所以，在迭代的过程中就不要使用list.remove()方法。 2. 单线程环境下的解决办法 既然知道原因了，那么如何解决呢？ 其实很简单，细心的朋友可能发现在Itr类中也给出了一个remove()方法： 123456789101112131415public void remove() &#123; if (lastRet == -1) throw new IllegalStateException(); checkForComodification(); try &#123; AbstractList.this.remove(lastRet); if (lastRet &lt; cursor) cursor--; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException e) &#123; throw new ConcurrentModificationException(); &#125;&#125; 在这个方法中，删除元素实际上调用的就是list.remove()方法，但是它多了一个操作： 1expectedModCount = modCount; 因此，在迭代器中如果要删除元素的话，需要调用Itr类的remove方法。 将上述代码改为下面这样就不会报错了： 123456789101112public class Test &#123; public static void main(String[] args) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(2); Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext())&#123; Integer integer = iterator.next(); if(integer==2) iterator.remove(); //注意这个地方 &#125; &#125;&#125; 3. 多线程环境下的解决办法 一般有2种解决办法： 1. 在使用iterator迭代的时候使用synchronized或者Lock进行同步； 2. 使用并发容器CopyOnWriteArrayList代替ArrayList和Vector。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://orzn.github.io/tags/java/"}]},{"title":"markov","slug":"markov","date":"2017-05-17T15:39:27.000Z","updated":"2017-05-19T15:23:05.762Z","comments":true,"path":"2017/05/17/markov/","link":"","permalink":"http://orzn.github.io/2017/05/17/markov/","excerpt":"","text":"马尔科夫也是一个经常遇到的名词了，马尔科夫过程，马尔科夫随机场等等，了解过，但一知半解，仍不是很理解，趁着学习图像处理这门课，把这些相关的东西也好好学学，整理整理。 马尔可夫链，因安德烈·马尔可夫（A.A.Markov，1856－1922）得名，是指数学中具有马尔可夫性质的离散事件随机过程。该过程中，在给定当前知识或信息的情况下，过去（即当前以前的历史状态）对于预测将来（即当前以后的未来状态）是无关的。随机漫步就是马尔可夫链的例子。其满足下面这个式子： 而马尔科夫过程呢，实际和马尔科夫链是一回事，只不过马尔科夫链是一个离散事件。 要说马尔科夫随机场，还需要先明确随机场的概念。随机场包含两个要素：位置（site），相空间（phase space）。当给每一个位置中按照某种分布随机赋予相空间的一个值之后，其全体就叫做随机场。我们不妨拿种地来打个比方。“位置”好比是一亩亩农田；“相空间”好比是种的各种庄稼。我们可以给不同的地种上不同的庄稼，这就好比给随机场的每个“位置”，赋予相空间里不同的值。所以，俗气点说，随机场就是在哪块地里种什么庄稼的事情。那么什么是马尔可夫随机场呢？还是拿种地打比方，如果任何一块地里种的庄稼的种类仅仅与它邻近的地里种的庄稼的种类有关，与其它地方的庄稼的种类无关，那么这些地里种的庄稼的集合，就是一个马尔可夫随机场。 要严格定义马尔科夫随机场，还需要引入邻域系统的的概念。 其实看了这幅图之后，不用细讲，也会大概明白邻域系统是个什么东西。在具体应用中，选取以x为中心，多大范围内的点为x的相邻像素点，不是固定不变的。X周围紫色的一圈称为4邻域系统，周围的所有8个点称为8邻域系统。令F={F1,…..,Fm}是一组定义在集合S上的随机变量，假如邻域系统中，对于任一点X，其取值只与邻域有关，那么我们就可以称F是一个马尔科夫随机场。 用马尔科夫随机场模型来解决实际问题时，如图像切割时，往往会用到马尔科夫随机场。","categories":[],"tags":[{"name":"图像处理","slug":"图像处理","permalink":"http://orzn.github.io/tags/图像处理/"}]},{"title":"markdown","slug":"markdown","date":"2017-05-09T05:09:16.000Z","updated":"2017-05-09T05:36:23.881Z","comments":true,"path":"2017/05/09/markdown/","link":"","permalink":"http://orzn.github.io/2017/05/09/markdown/","excerpt":"","text":"Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。当然，我使用这个主要是因为github的锅。别的不多说了，这里简单介绍一些Markdown的基本语法： 1. 标题 对于标题，有两种写法：Setext和atx形式。Setext形式是利用底线的形式，利用=（最高阶标题）和-（第二节标题）；Atx形式是在行首插入1到6个#，对应标题1到6阶。 Setext形式：A First Level Header =（几个等于号都行） A Second Level Header - A First Level Header=A Second Level Header- 经测试，好像Setex并不靠谱。。。 Atx形式：#A First Level Header ##A Second Level Header A First Level HeaderA Second Level Header2. 段落 想要分段需要在两个段落中间加入一个以上的空行。或者可以在上一个段末加上两个空格。不过，效果不同。 This is a paragraph. This is the second paragraph This is a paragraph. This is the second paragraph This is a paragraph.(space)(space) This is the second paragraph This is a paragraph.This is the second paragraph 3. 粗斜体 粗体，斜体也经常会用到。斜体就是文本两端加上＊或者＿，而粗体是在两边各加两个，粗斜体是加三个。 *斜体文本* _斜体文本_ 斜体文本 斜体文本 **粗体文本** __粗体文本__ 粗体文本 粗体文本 ***粗斜体文本*** ___粗斜体文本___ 粗斜体文本 粗斜体文本 4. 列表无序列表以下三种写法都行： - 列表文本前使用 [减号+空格] + 列表文本前使用 [加号+空格] * 列表文本前使用 [星号+空格] 列表文本前使用 [减号+空格] 列表文本前使用 [加号+空格] 列表文本前使用 [星号+空格] 有序列表注意： 数字后面有个点. 1. 列表前使用 [数字+空格] 2. 我们会自动帮你添加数字 7. 不用担心数字不对，显示的时候我们会自动把这行的 7 纠正为 3 列表前使用 [数字+空格] 我们会自动帮你添加数字 不用担心数字不对，显示的时候我们会自动把这行的 7 纠正为 3 除了普通的列表以外，我们也许还会用到列表的嵌套，这时候，只需要在前面加上四个空格。 5. 链接常用的链接方法：文字链接 [this is my hourse](http://www.orzn.ml) 网址链接 &lt;http://www.orzn.ml&gt; 文字链接 this is my hourse 网址链接 http://www.orzn.ml 高级链接方法：这个链接用 1 作为网址变量 [Google][1].这个链接用 yahoo 作为网址变量 [Yahoo!][yahoo]. 然后在文档的结尾为变量赋值（网址） [1]: http://www.google.com/ [yahoo]: http://www.yahoo.com/ 这个链接用 1 作为网址变量 Google.这个链接用 yahoo 作为网址变量 Yahoo!.然后在文档的结尾为变量赋值（网址） 以上两种写法显示效果是一样的，第二种方法在文档的结尾所写的网址，也不会显示。 6. 图片 跟链接的方法区别在于前面加了个感叹号 !，这样是不是觉得好记多了呢？也可以使用 HTML 的图片语法来自定义图片的宽高大小: &lt;img src=&quot;http://ww4.sinaimg.cn/mw690/7b405dbbgw1e9ko16tk6dj20pc0fuwhw.jpg&quot; width=&quot;400&quot; height=&quot;100&quot;&gt; 7. 代码 想要在文中高亮语句中的某个函数名或关键字，可以使用 `function_name()` 实现function_name()。如果是代码段，可以用12345```javascript$(document).ready(function () &#123; alert(&apos;hello world&apos;);&#125;); 123$(document).ready(function () &#123; alert('hello world');&#125;); PS: 如果你的描述中需要用到 markdown 的符号，比如 # * 等，但又不想它被转义，这时候可以在这些符号前加反斜杠，如 \\ \\# \\* 进行避免。 目前只支持部分段内 HTML 元素效果，包括&lt;kdb&gt; &lt;b&gt; &lt;i&gt; &lt;em&gt; &lt;sup&gt; &lt;sub&gt; &lt;br&gt;当然，前面提到的img也是。 markdown里面段落前是不能空两格的，我们可以将输入法调成全角，然后在段首敲两个空格键就可以了。","categories":[],"tags":[{"name":"markdown","slug":"markdown","permalink":"http://orzn.github.io/tags/markdown/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-05-07T16:50:17.733Z","updated":"2017-05-08T04:48:35.899Z","comments":true,"path":"2017/05/08/hello-world/","link":"","permalink":"http://orzn.github.io/2017/05/08/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}